[2025-05-10 22:15:53] Starting training session
Model configuration: IMAGE_SIZE=(416, 416), BATCH_SIZE=16, EPOCHS=50, LEARNING_RATE=0.0001

[2025-05-10 22:15:53] === Starting Valorany Detector ===
[2025-05-10 22:15:53] Training data: ../tf_files/train.record
[2025-05-10 22:15:53] Validation data: ../tf_files/valid.record
[2025-05-10 22:15:53] Loading data from ../tf_files/train.record and ../tf_files/valid.record
[2025-05-10 22:15:53] Estimating dataset sizes...
[2025-05-10 22:15:53] Train dataset size: ~337 batches (approx. 5385 examples)
[2025-05-10 22:15:53] Validation dataset size: ~33 batches (approx. 514 examples)
[2025-05-10 22:15:53] Creating model...
[2025-05-10 22:15:54] Starting model training...
[2025-05-10 22:15:54] === Training Started ===
[2025-05-10 22:15:54] Model structure:
[2025-05-10 22:15:54] Total layers: 160
[2025-05-10 22:15:54] Total parameters: 9,344,081
[2025-05-10 22:15:54] Trainable parameters: 7,084,561
[2025-05-10 22:15:54] Non-trainable parameters: 2,259,520
[2025-05-10 22:15:57] Batch 0 - Loss: 571.620667
[2025-05-10 22:15:59] Batch 5 - Loss: 475.405762
[2025-05-10 22:16:01] Batch 10 - Loss: 437.393341
[2025-05-10 22:16:03] Batch 15 - Loss: 409.627258
[2025-05-10 22:16:04] Batch 20 - Loss: 388.492981
[2025-05-10 22:16:06] Batch 25 - Loss: 366.103363
[2025-05-10 22:16:08] Batch 30 - Loss: 350.300598
[2025-05-10 22:16:10] Batch 35 - Loss: 333.590942
[2025-05-10 22:16:11] Batch 40 - Loss: 318.756744
[2025-05-10 22:16:13] Batch 45 - Loss: 306.572327
[2025-05-10 22:16:15] Batch 50 - Loss: 293.814331
[2025-05-10 22:16:17] Batch 55 - Loss: 282.382507
[2025-05-10 22:16:18] Batch 60 - Loss: 271.573120
[2025-05-10 22:16:20] Batch 65 - Loss: 260.816650
[2025-05-10 22:16:22] Batch 70 - Loss: 251.154877
[2025-05-10 22:16:24] Batch 75 - Loss: 241.514648
[2025-05-10 22:16:26] Batch 80 - Loss: 232.565796
[2025-05-10 22:16:27] Batch 85 - Loss: 223.777451
[2025-05-10 22:16:29] Batch 90 - Loss: 215.781876
[2025-05-10 22:16:31] Batch 95 - Loss: 207.912643
[2025-05-10 22:16:39] === Epoch 1/50 Summary ===
Training Loss: 201.883301
Validation Loss: 398.145203
Learning Rate: 0.00003000
[2025-05-10 22:16:39] Batch 0 - Loss: 58.937927
[2025-05-10 22:16:41] Batch 5 - Loss: 55.806011
[2025-05-10 22:16:43] Batch 10 - Loss: 54.559299
[2025-05-10 22:16:44] Batch 15 - Loss: 51.695618
[2025-05-10 22:16:46] Batch 20 - Loss: 49.751232
[2025-05-10 22:16:48] Batch 25 - Loss: 47.562080
[2025-05-10 22:16:50] Batch 30 - Loss: 45.352016
[2025-05-10 22:16:51] Batch 35 - Loss: 43.367271
[2025-05-10 22:16:53] Batch 40 - Loss: 41.550014
[2025-05-10 22:16:55] Batch 45 - Loss: 39.999527
[2025-05-10 22:16:57] Batch 50 - Loss: 38.616802
[2025-05-10 22:16:58] Batch 55 - Loss: 37.240810
[2025-05-10 22:17:00] Batch 60 - Loss: 36.058792
[2025-05-10 22:17:02] Batch 65 - Loss: 34.823795
[2025-05-10 22:17:04] Batch 70 - Loss: 33.798958
[2025-05-10 22:17:06] Batch 75 - Loss: 32.779732
[2025-05-10 22:17:07] Batch 80 - Loss: 31.867105
[2025-05-10 22:17:09] Batch 85 - Loss: 30.964165
[2025-05-10 22:17:11] Batch 90 - Loss: 30.044704
[2025-05-10 22:17:13] Batch 95 - Loss: 29.306620
[2025-05-10 22:17:20] === Epoch 2/50 Summary ===
Training Loss: 28.783455
Validation Loss: 56.003609
Learning Rate: 0.00003000
[2025-05-10 22:17:21] Batch 0 - Loss: 12.004791
[2025-05-10 22:17:22] Batch 5 - Loss: 13.494983
[2025-05-10 22:17:24] Batch 10 - Loss: 13.764848
[2025-05-10 22:17:26] Batch 15 - Loss: 13.870254
[2025-05-10 22:17:27] Batch 20 - Loss: 14.256817
[2025-05-10 22:17:29] Batch 25 - Loss: 13.872416
[2025-05-10 22:17:31] Batch 30 - Loss: 14.164310
[2025-05-10 22:17:33] Batch 35 - Loss: 14.050261
[2025-05-10 22:17:34] Batch 40 - Loss: 13.843514
[2025-05-10 22:17:36] Batch 45 - Loss: 13.706150
[2025-05-10 22:17:38] Batch 50 - Loss: 13.449389
[2025-05-10 22:17:40] Batch 55 - Loss: 13.182836
[2025-05-10 22:17:41] Batch 60 - Loss: 13.027765
[2025-05-10 22:17:43] Batch 65 - Loss: 12.824391
[2025-05-10 22:17:45] Batch 70 - Loss: 12.675091
[2025-05-10 22:17:47] Batch 75 - Loss: 12.484143
[2025-05-10 22:17:48] Batch 80 - Loss: 12.339478
[2025-05-10 22:17:50] Batch 85 - Loss: 12.170980
[2025-05-10 22:17:52] Batch 90 - Loss: 12.012464
[2025-05-10 22:17:53] Batch 95 - Loss: 11.833332
[2025-05-10 22:18:01] === Epoch 3/50 Summary ===
Training Loss: 11.701210
Validation Loss: 31.929480
Learning Rate: 0.00003000
[2025-05-10 22:18:01] Batch 0 - Loss: 7.613416
[2025-05-10 22:18:03] Batch 5 - Loss: 8.984876
[2025-05-10 22:18:04] Batch 10 - Loss: 8.853949
[2025-05-10 22:18:06] Batch 15 - Loss: 8.733052
[2025-05-10 22:18:08] Batch 20 - Loss: 8.359372
[2025-05-10 22:18:10] Batch 25 - Loss: 8.336050
[2025-05-10 22:18:11] Batch 30 - Loss: 8.207746
[2025-05-10 22:18:13] Batch 35 - Loss: 8.220943
[2025-05-10 22:18:19] === Epoch 4/50 Summary ===
Training Loss: 8.209242
Validation Loss: 22.435780
Learning Rate: 0.00003000
[2025-05-10 22:18:20] Batch 0 - Loss: 7.841505
[2025-05-10 22:18:21] Batch 5 - Loss: 7.686879
[2025-05-10 22:18:23] Batch 10 - Loss: 8.219102
[2025-05-10 22:18:25] Batch 15 - Loss: 8.141960
[2025-05-10 22:18:27] Batch 20 - Loss: 8.116299
[2025-05-10 22:18:28] Batch 25 - Loss: 8.285154
[2025-05-10 22:18:30] Batch 30 - Loss: 8.235445
[2025-05-10 22:18:32] Batch 35 - Loss: 8.204626
[2025-05-10 22:18:34] Batch 40 - Loss: 8.200920
[2025-05-10 22:18:35] Batch 45 - Loss: 8.135816
[2025-05-10 22:18:37] Batch 50 - Loss: 8.031981
[2025-05-10 22:18:39] Batch 55 - Loss: 7.908499
[2025-05-10 22:18:41] Batch 60 - Loss: 7.890037
[2025-05-10 22:18:42] Batch 65 - Loss: 7.771943
[2025-05-10 22:18:44] Batch 70 - Loss: 7.710515
[2025-05-10 22:18:46] Batch 75 - Loss: 7.646372
[2025-05-10 22:18:48] Batch 80 - Loss: 7.575816
[2025-05-10 22:18:49] Batch 85 - Loss: 7.524927
[2025-05-10 22:18:51] Batch 90 - Loss: 7.450682
[2025-05-10 22:18:53] Batch 95 - Loss: 7.386570
[2025-05-10 22:19:00] === Epoch 5/50 Summary ===
Training Loss: 7.316062
Validation Loss: 22.019632
Learning Rate: 0.00003000
[2025-05-10 22:19:00] Generating detection visualizations for epoch 5...
[2025-05-10 22:19:01] Saved visualization to trained_models/custom_detector\visualizations\epoch_5\sample_1.png
[2025-05-10 22:19:01] Saved visualization to trained_models/custom_detector\visualizations\epoch_5\sample_2.png
[2025-05-10 22:19:02] Saved visualization to trained_models/custom_detector\visualizations\epoch_5\sample_3.png
[2025-05-10 22:19:02] Batch 0 - Loss: 6.634845
[2025-05-10 22:19:04] Batch 5 - Loss: 5.879875
[2025-05-10 22:19:05] Batch 10 - Loss: 5.572734
[2025-05-10 22:19:07] Batch 15 - Loss: 5.538764
[2025-05-10 22:19:09] Batch 20 - Loss: 5.800128
[2025-05-10 22:19:11] Batch 25 - Loss: 5.767272
[2025-05-10 22:19:13] Batch 30 - Loss: 5.706184
[2025-05-10 22:19:14] Batch 35 - Loss: 5.736670
[2025-05-10 22:19:16] Batch 40 - Loss: 5.704789
[2025-05-10 22:19:18] Batch 45 - Loss: 5.719440
[2025-05-10 22:19:20] Batch 50 - Loss: 5.704337
[2025-05-10 22:19:21] Batch 55 - Loss: 5.743865
[2025-05-10 22:19:23] Batch 60 - Loss: 5.697096
[2025-05-10 22:19:25] Batch 65 - Loss: 5.679045
[2025-05-10 22:19:27] Batch 70 - Loss: 5.644585
[2025-05-10 22:19:28] Batch 75 - Loss: 5.638300
[2025-05-10 22:19:30] Batch 80 - Loss: 5.606446
[2025-05-10 22:19:32] Batch 85 - Loss: 5.588385
[2025-05-10 22:19:34] Batch 90 - Loss: 5.538928
[2025-05-10 22:19:35] Batch 95 - Loss: 5.515798
[2025-05-10 22:19:43] === Epoch 6/50 Summary ===
Training Loss: 5.471388
Validation Loss: 10.242929
Learning Rate: 0.00003000
[2025-05-10 22:19:43] Batch 0 - Loss: 5.607552
[2025-05-10 22:19:45] Batch 5 - Loss: 5.437804
[2025-05-10 22:19:46] Batch 10 - Loss: 5.084236
[2025-05-10 22:19:48] Batch 15 - Loss: 4.954671
[2025-05-10 22:19:50] Batch 20 - Loss: 4.851342
[2025-05-10 22:19:52] Batch 25 - Loss: 4.886366
[2025-05-10 22:19:53] Batch 30 - Loss: 4.964523
[2025-05-10 22:19:55] Batch 35 - Loss: 4.912879
[2025-05-10 22:19:57] Batch 40 - Loss: 4.855871
[2025-05-10 22:19:58] Batch 45 - Loss: 4.890736
[2025-05-10 22:20:00] Batch 50 - Loss: 4.909742
[2025-05-10 22:20:02] Batch 55 - Loss: 4.862899
[2025-05-10 22:20:04] Batch 60 - Loss: 4.856218
[2025-05-10 22:20:05] Batch 65 - Loss: 4.838693
[2025-05-10 22:20:07] Batch 70 - Loss: 4.825805
[2025-05-10 22:20:09] Batch 75 - Loss: 4.817400
[2025-05-10 22:20:11] Batch 80 - Loss: 4.766613
[2025-05-10 22:20:12] Batch 85 - Loss: 4.730503
[2025-05-10 22:20:14] Batch 90 - Loss: 4.700686
[2025-05-10 22:20:16] Batch 95 - Loss: 4.660238
[2025-05-10 22:20:24] === Epoch 7/50 Summary ===
Training Loss: 4.677998
Validation Loss: 9.041483
Learning Rate: 0.00003000
[2025-05-10 22:20:24] Batch 0 - Loss: 3.241767
[2025-05-10 22:20:26] Batch 5 - Loss: 4.093953
[2025-05-10 22:20:28] Batch 10 - Loss: 4.111080
[2025-05-10 22:20:29] Batch 15 - Loss: 4.025035
[2025-05-10 22:20:31] Batch 20 - Loss: 3.975340
[2025-05-10 22:20:33] Batch 25 - Loss: 3.962474
[2025-05-10 22:20:35] Batch 30 - Loss: 3.960819
[2025-05-10 22:20:36] Batch 35 - Loss: 3.989475
[2025-05-10 22:20:42] === Epoch 8/50 Summary ===
Training Loss: 3.978662
Validation Loss: 8.236156
Learning Rate: 0.00003000
[2025-05-10 22:20:43] Batch 0 - Loss: 5.224229
[2025-05-10 22:20:45] Batch 5 - Loss: 5.140969
[2025-05-10 22:20:46] Batch 10 - Loss: 4.864044
[2025-05-10 22:20:48] Batch 15 - Loss: 4.776538
[2025-05-10 22:20:50] Batch 20 - Loss: 4.740705
[2025-05-10 22:20:52] Batch 25 - Loss: 4.672415
[2025-05-10 22:20:54] Batch 30 - Loss: 4.593229
[2025-05-10 22:20:55] Batch 35 - Loss: 4.584446
[2025-05-10 22:20:57] Batch 40 - Loss: 4.566217
[2025-05-10 22:20:59] Batch 45 - Loss: 4.565374
[2025-05-10 22:21:01] Batch 50 - Loss: 4.567018
[2025-05-10 22:21:02] Batch 55 - Loss: 4.530069
[2025-05-10 22:21:04] Batch 60 - Loss: 4.463068
[2025-05-10 22:21:06] Batch 65 - Loss: 4.437617
[2025-05-10 22:21:08] Batch 70 - Loss: 4.412294
[2025-05-10 22:21:09] Batch 75 - Loss: 4.377812
[2025-05-10 22:21:11] Batch 80 - Loss: 4.359076
[2025-05-10 22:21:13] Batch 85 - Loss: 4.335975
[2025-05-10 22:21:15] Batch 90 - Loss: 4.307935
[2025-05-10 22:21:16] Batch 95 - Loss: 4.273450
[2025-05-10 22:21:24] === Epoch 9/50 Summary ===
Training Loss: 4.264095
Validation Loss: 9.204663
Learning Rate: 0.00003000
[2025-05-10 22:21:24] Batch 0 - Loss: 3.820651
[2025-05-10 22:21:26] Batch 5 - Loss: 3.963280
[2025-05-10 22:21:27] Batch 10 - Loss: 4.014220
[2025-05-10 22:21:29] Batch 15 - Loss: 4.056743
[2025-05-10 22:21:31] Batch 20 - Loss: 4.027190
[2025-05-10 22:21:32] Batch 25 - Loss: 4.032657
[2025-05-10 22:21:34] Batch 30 - Loss: 3.996962
[2025-05-10 22:21:36] Batch 35 - Loss: 3.921123
[2025-05-10 22:21:38] Batch 40 - Loss: 3.939318
[2025-05-10 22:21:39] Batch 45 - Loss: 3.917539
[2025-05-10 22:21:41] Batch 50 - Loss: 3.920191
[2025-05-10 22:21:43] Batch 55 - Loss: 3.897638
[2025-05-10 22:21:45] Batch 60 - Loss: 3.906920
[2025-05-10 22:21:46] Batch 65 - Loss: 3.878890
[2025-05-10 22:21:48] Batch 70 - Loss: 3.884360
[2025-05-10 22:21:50] Batch 75 - Loss: 3.869407
[2025-05-10 22:21:52] Batch 80 - Loss: 3.845552
[2025-05-10 22:21:53] Batch 85 - Loss: 3.851985
[2025-05-10 22:21:55] Batch 90 - Loss: 3.820227
[2025-05-10 22:21:57] Batch 95 - Loss: 3.824672
[2025-05-10 22:22:04] === Epoch 10/50 Summary ===
Training Loss: 3.817429
Validation Loss: 6.401149
Learning Rate: 0.00003000
[2025-05-10 22:22:04] Generating detection visualizations for epoch 10...
[2025-05-10 22:22:04] Saved visualization to trained_models/custom_detector\visualizations\epoch_10\sample_1.png
[2025-05-10 22:22:05] Saved visualization to trained_models/custom_detector\visualizations\epoch_10\sample_2.png
[2025-05-10 22:22:05] Saved visualization to trained_models/custom_detector\visualizations\epoch_10\sample_3.png
[2025-05-10 22:22:05] Batch 0 - Loss: 3.254752
[2025-05-10 22:22:07] Batch 5 - Loss: 3.367008
[2025-05-10 22:22:09] Batch 10 - Loss: 3.509307
[2025-05-10 22:22:10] Batch 15 - Loss: 3.516844
[2025-05-10 22:22:12] Batch 20 - Loss: 3.509159
[2025-05-10 22:22:14] Batch 25 - Loss: 3.460667
[2025-05-10 22:22:16] Batch 30 - Loss: 3.535455
[2025-05-10 22:22:17] Batch 35 - Loss: 3.533376
[2025-05-10 22:22:19] Batch 40 - Loss: 3.502666
[2025-05-10 22:22:21] Batch 45 - Loss: 3.523372
[2025-05-10 22:22:23] Batch 50 - Loss: 3.494080
[2025-05-10 22:22:24] Batch 55 - Loss: 3.492081
[2025-05-10 22:22:26] Batch 60 - Loss: 3.497873
[2025-05-10 22:22:28] Batch 65 - Loss: 3.476583
[2025-05-10 22:22:29] Batch 70 - Loss: 3.471109
[2025-05-10 22:22:31] Batch 75 - Loss: 3.452025
[2025-05-10 22:22:33] Batch 80 - Loss: 3.437612
[2025-05-10 22:22:34] Batch 85 - Loss: 3.416228
[2025-05-10 22:22:36] Batch 90 - Loss: 3.412140
[2025-05-10 22:22:38] Batch 95 - Loss: 3.391395
[2025-05-10 22:22:45] === Epoch 11/50 Summary ===
Training Loss: 3.391402
Validation Loss: 6.387684
Learning Rate: 0.00003000
[2025-05-10 22:22:45] Batch 0 - Loss: 2.677111
[2025-05-10 22:22:47] Batch 5 - Loss: 3.067173
[2025-05-10 22:22:49] Batch 10 - Loss: 3.089037
[2025-05-10 22:22:51] Batch 15 - Loss: 3.205453
[2025-05-10 22:22:52] Batch 20 - Loss: 3.193954
[2025-05-10 22:22:54] Batch 25 - Loss: 3.181238
[2025-05-10 22:22:56] Batch 30 - Loss: 3.139574
[2025-05-10 22:22:57] Batch 35 - Loss: 3.150833
[2025-05-10 22:23:03] === Epoch 12/50 Summary ===
Training Loss: 3.164393
Validation Loss: 6.113429
Learning Rate: 0.00003000
[2025-05-10 22:23:04] Batch 0 - Loss: 3.940072
[2025-05-10 22:23:06] Batch 5 - Loss: 3.650252
[2025-05-10 22:23:07] Batch 10 - Loss: 3.757594
[2025-05-10 22:23:09] Batch 15 - Loss: 3.701383
[2025-05-10 22:23:11] Batch 20 - Loss: 3.756647
[2025-05-10 22:23:13] Batch 25 - Loss: 3.718722
[2025-05-10 22:23:14] Batch 30 - Loss: 3.735170
[2025-05-10 22:23:16] Batch 35 - Loss: 3.681188
[2025-05-10 22:23:18] Batch 40 - Loss: 3.628866
[2025-05-10 22:23:20] Batch 45 - Loss: 3.596596
[2025-05-10 22:23:21] Batch 50 - Loss: 3.576032
[2025-05-10 22:23:23] Batch 55 - Loss: 3.570002
[2025-05-10 22:23:25] Batch 60 - Loss: 3.580109
[2025-05-10 22:23:26] Batch 65 - Loss: 3.560316
[2025-05-10 22:23:28] Batch 70 - Loss: 3.535615
[2025-05-10 22:23:30] Batch 75 - Loss: 3.495169
[2025-05-10 22:23:32] Batch 80 - Loss: 3.479447
[2025-05-10 22:23:33] Batch 85 - Loss: 3.472197
[2025-05-10 22:23:35] Batch 90 - Loss: 3.458038
[2025-05-10 22:23:37] Batch 95 - Loss: 3.412502
[2025-05-10 22:23:44] === Epoch 13/50 Summary ===
Training Loss: 3.399275
Validation Loss: 6.152863
Learning Rate: 0.00003000
[2025-05-10 22:23:44] Batch 0 - Loss: 3.457778
[2025-05-10 22:23:46] Batch 5 - Loss: 3.287057
[2025-05-10 22:23:48] Batch 10 - Loss: 3.063004
[2025-05-10 22:23:49] Batch 15 - Loss: 3.093078
[2025-05-10 22:23:51] Batch 20 - Loss: 3.108418
[2025-05-10 22:23:53] Batch 25 - Loss: 3.125021
[2025-05-10 22:23:55] Batch 30 - Loss: 3.117545
[2025-05-10 22:23:56] Batch 35 - Loss: 3.097612
[2025-05-10 22:23:58] Batch 40 - Loss: 3.095650
[2025-05-10 22:24:00] Batch 45 - Loss: 3.119989
[2025-05-10 22:24:01] Batch 50 - Loss: 3.077209
[2025-05-10 22:24:03] Batch 55 - Loss: 3.076033
[2025-05-10 22:24:05] Batch 60 - Loss: 3.092709
[2025-05-10 22:24:07] Batch 65 - Loss: 3.084851
[2025-05-10 22:24:08] Batch 70 - Loss: 3.087794
[2025-05-10 22:24:10] Batch 75 - Loss: 3.115026
[2025-05-10 22:24:12] Batch 80 - Loss: 3.105408
[2025-05-10 22:24:13] Batch 85 - Loss: 3.083110
[2025-05-10 22:24:15] Batch 90 - Loss: 3.078984
[2025-05-10 22:24:17] Batch 95 - Loss: 3.064696
[2025-05-10 22:24:24] === Epoch 14/50 Summary ===
Training Loss: 3.045445
Validation Loss: 5.726531
Learning Rate: 0.00003000
[2025-05-10 22:24:25] Batch 0 - Loss: 3.264933
[2025-05-10 22:24:26] Batch 5 - Loss: 3.114327
[2025-05-10 22:24:28] Batch 10 - Loss: 3.196376
[2025-05-10 22:24:30] Batch 15 - Loss: 3.200353
[2025-05-10 22:24:32] Batch 20 - Loss: 3.219120
[2025-05-10 22:24:33] Batch 25 - Loss: 3.216517
[2025-05-10 22:24:35] Batch 30 - Loss: 3.227943
[2025-05-10 22:24:37] Batch 35 - Loss: 3.162344
[2025-05-10 22:24:38] Batch 40 - Loss: 3.115208
[2025-05-10 22:24:40] Batch 45 - Loss: 3.109848
[2025-05-10 22:24:42] Batch 50 - Loss: 3.103663
[2025-05-10 22:24:44] Batch 55 - Loss: 3.043676
[2025-05-10 22:24:45] Batch 60 - Loss: 3.042352
[2025-05-10 22:24:47] Batch 65 - Loss: 3.016030
[2025-05-10 22:24:49] Batch 70 - Loss: 3.016246
[2025-05-10 22:24:50] Batch 75 - Loss: 3.000821
[2025-05-10 22:24:52] Batch 80 - Loss: 2.979131
[2025-05-10 22:24:54] Batch 85 - Loss: 2.967176
[2025-05-10 22:24:56] Batch 90 - Loss: 2.969358
[2025-05-10 22:24:57] Batch 95 - Loss: 2.963008
[2025-05-10 22:25:05] === Epoch 15/50 Summary ===
Training Loss: 2.946360
Validation Loss: 5.497612
Learning Rate: 0.00003000
[2025-05-10 22:25:05] Generating detection visualizations for epoch 15...
[2025-05-10 22:25:05] Saved visualization to trained_models/custom_detector\visualizations\epoch_15\sample_1.png
[2025-05-10 22:25:05] Saved visualization to trained_models/custom_detector\visualizations\epoch_15\sample_2.png
[2025-05-10 22:25:06] Saved visualization to trained_models/custom_detector\visualizations\epoch_15\sample_3.png
[2025-05-10 22:25:06] Batch 0 - Loss: 2.403869
[2025-05-10 22:25:08] Batch 5 - Loss: 2.432872
[2025-05-10 22:25:09] Batch 10 - Loss: 2.532844
[2025-05-10 22:25:11] Batch 15 - Loss: 2.620028
[2025-05-10 22:25:13] Batch 20 - Loss: 2.661254
[2025-05-10 22:25:15] Batch 25 - Loss: 2.653074
[2025-05-10 22:25:16] Batch 30 - Loss: 2.640507
[2025-05-10 22:25:18] Batch 35 - Loss: 2.664522
[2025-05-10 22:25:24] === Epoch 16/50 Summary ===
Training Loss: 2.655297
Validation Loss: 5.617923
Learning Rate: 0.00003000
[2025-05-10 22:25:24] Batch 0 - Loss: 3.888834
[2025-05-10 22:25:26] Batch 5 - Loss: 3.209822
[2025-05-10 22:25:28] Batch 10 - Loss: 3.088686
[2025-05-10 22:25:30] Batch 15 - Loss: 3.092393
[2025-05-10 22:25:31] Batch 20 - Loss: 3.025801
[2025-05-10 22:25:33] Batch 25 - Loss: 3.089337
[2025-05-10 22:25:35] Batch 30 - Loss: 3.041230
[2025-05-10 22:25:37] Batch 35 - Loss: 3.013569
[2025-05-10 22:25:38] Batch 40 - Loss: 2.993508
[2025-05-10 22:25:40] Batch 45 - Loss: 2.988759
[2025-05-10 22:25:42] Batch 50 - Loss: 2.965568
[2025-05-10 22:25:44] Batch 55 - Loss: 2.961735
[2025-05-10 22:25:45] Batch 60 - Loss: 2.942632
[2025-05-10 22:25:47] Batch 65 - Loss: 2.923252
[2025-05-10 22:25:49] Batch 70 - Loss: 2.919795
[2025-05-10 22:25:50] Batch 75 - Loss: 2.923563
[2025-05-10 22:25:52] Batch 80 - Loss: 2.907141
[2025-05-10 22:25:54] Batch 85 - Loss: 2.913873
[2025-05-10 22:25:56] Batch 90 - Loss: 2.911566
[2025-05-10 22:25:58] Batch 95 - Loss: 2.894979
[2025-05-10 22:26:05] === Epoch 17/50 Summary ===
Training Loss: 2.888701
Validation Loss: 5.727519
Learning Rate: 0.00003000
[2025-05-10 22:26:05] Batch 0 - Loss: 2.382969
[2025-05-10 22:26:07] Batch 5 - Loss: 2.684473
[2025-05-10 22:26:09] Batch 10 - Loss: 2.769273
[2025-05-10 22:26:11] Batch 15 - Loss: 2.757300
[2025-05-10 22:26:12] Batch 20 - Loss: 2.803794
[2025-05-10 22:26:14] Batch 25 - Loss: 2.756839
[2025-05-10 22:26:16] Batch 30 - Loss: 2.759280
[2025-05-10 22:26:18] Batch 35 - Loss: 2.766418
[2025-05-10 22:26:19] Batch 40 - Loss: 2.724259
[2025-05-10 22:26:21] Batch 45 - Loss: 2.761390
[2025-05-10 22:26:23] Batch 50 - Loss: 2.761462
[2025-05-10 22:26:25] Batch 55 - Loss: 2.746307
[2025-05-10 22:26:26] Batch 60 - Loss: 2.761571
[2025-05-10 22:26:28] Batch 65 - Loss: 2.749064
[2025-05-10 22:26:30] Batch 70 - Loss: 2.737005
[2025-05-10 22:26:32] Batch 75 - Loss: 2.712579
[2025-05-10 22:26:33] Batch 80 - Loss: 2.697089
[2025-05-10 22:26:35] Batch 85 - Loss: 2.685653
[2025-05-10 22:26:37] Batch 90 - Loss: 2.699127
[2025-05-10 22:26:39] Batch 95 - Loss: 2.699455
[2025-05-10 22:26:46] === Epoch 18/50 Summary ===
Training Loss: 2.690967
Validation Loss: 5.208625
Learning Rate: 0.00003000
[2025-05-10 22:26:46] Batch 0 - Loss: 2.622669
[2025-05-10 22:26:48] Batch 5 - Loss: 2.771634
[2025-05-10 22:26:50] Batch 10 - Loss: 2.568588
[2025-05-10 22:26:52] Batch 15 - Loss: 2.583930
[2025-05-10 22:26:53] Batch 20 - Loss: 2.535290
[2025-05-10 22:26:55] Batch 25 - Loss: 2.539718
[2025-05-10 22:26:57] Batch 30 - Loss: 2.510666
[2025-05-10 22:26:58] Batch 35 - Loss: 2.524363
[2025-05-10 22:27:00] Batch 40 - Loss: 2.525728
[2025-05-10 22:27:02] Batch 45 - Loss: 2.506957
[2025-05-10 22:27:04] Batch 50 - Loss: 2.507729
[2025-05-10 22:27:05] Batch 55 - Loss: 2.517688
[2025-05-10 22:27:07] Batch 60 - Loss: 2.515884
[2025-05-10 22:27:09] Batch 65 - Loss: 2.546553
[2025-05-10 22:27:11] Batch 70 - Loss: 2.550629
[2025-05-10 22:27:12] Batch 75 - Loss: 2.533503
[2025-05-10 22:27:14] Batch 80 - Loss: 2.525005
[2025-05-10 22:27:16] Batch 85 - Loss: 2.518409
[2025-05-10 22:27:17] Batch 90 - Loss: 2.512759
[2025-05-10 22:27:19] Batch 95 - Loss: 2.531426
[2025-05-10 22:27:26] === Epoch 19/50 Summary ===
Training Loss: 2.529141
Validation Loss: 5.388520
Learning Rate: 0.00003000
[2025-05-10 22:27:27] Batch 0 - Loss: 2.034503
[2025-05-10 22:27:28] Batch 5 - Loss: 2.162209
[2025-05-10 22:27:30] Batch 10 - Loss: 2.290203
[2025-05-10 22:27:32] Batch 15 - Loss: 2.254471
[2025-05-10 22:27:33] Batch 20 - Loss: 2.317789
[2025-05-10 22:27:35] Batch 25 - Loss: 2.328213
[2025-05-10 22:27:37] Batch 30 - Loss: 2.310127
[2025-05-10 22:27:39] Batch 35 - Loss: 2.335681
[2025-05-10 22:27:44] === Epoch 20/50 Summary ===
Training Loss: 2.331639
Validation Loss: 5.367637
Learning Rate: 0.00003000
[2025-05-10 22:27:44] Generating detection visualizations for epoch 20...
[2025-05-10 22:27:45] Saved visualization to trained_models/custom_detector\visualizations\epoch_20\sample_1.png
[2025-05-10 22:27:45] Saved visualization to trained_models/custom_detector\visualizations\epoch_20\sample_2.png
[2025-05-10 22:27:46] Saved visualization to trained_models/custom_detector\visualizations\epoch_20\sample_3.png
[2025-05-10 22:27:46] Batch 0 - Loss: 2.324857
[2025-05-10 22:27:48] Batch 5 - Loss: 2.634822
[2025-05-10 22:27:50] Batch 10 - Loss: 2.699142
[2025-05-10 22:27:51] Batch 15 - Loss: 2.689768
[2025-05-10 22:27:53] Batch 20 - Loss: 2.652825
[2025-05-10 22:27:55] Batch 25 - Loss: 2.703779
[2025-05-10 22:27:56] Batch 30 - Loss: 2.725353
[2025-05-10 22:27:58] Batch 35 - Loss: 2.771041
[2025-05-10 22:28:00] Batch 40 - Loss: 2.766682
[2025-05-10 22:28:02] Batch 45 - Loss: 2.747756
[2025-05-10 22:28:03] Batch 50 - Loss: 2.747945
[2025-05-10 22:28:05] Batch 55 - Loss: 2.708772
[2025-05-10 22:28:07] Batch 60 - Loss: 2.679789
[2025-05-10 22:28:09] Batch 65 - Loss: 2.664927
[2025-05-10 22:28:10] Batch 70 - Loss: 2.637006
[2025-05-10 22:28:12] Batch 75 - Loss: 2.619814
[2025-05-10 22:28:14] Batch 80 - Loss: 2.609380
[2025-05-10 22:28:16] Batch 85 - Loss: 2.598776
[2025-05-10 22:28:17] Batch 90 - Loss: 2.588842
[2025-05-10 22:28:19] Batch 95 - Loss: 2.569859
[2025-05-10 22:28:26] === Epoch 21/50 Summary ===
Training Loss: 2.568814
Validation Loss: 5.403082
Learning Rate: 0.00003000
[2025-05-10 22:28:27] Batch 0 - Loss: 2.083392
[2025-05-10 22:28:28] Batch 5 - Loss: 2.264668
[2025-05-10 22:28:30] Batch 10 - Loss: 2.349964
[2025-05-10 22:28:32] Batch 15 - Loss: 2.373631
[2025-05-10 22:28:34] Batch 20 - Loss: 2.358755
[2025-05-10 22:28:35] Batch 25 - Loss: 2.379768
[2025-05-10 22:28:37] Batch 30 - Loss: 2.366808
[2025-05-10 22:28:39] Batch 35 - Loss: 2.357980
[2025-05-10 22:28:41] Batch 40 - Loss: 2.385195
[2025-05-10 22:28:42] Batch 45 - Loss: 2.395304
[2025-05-10 22:28:44] Batch 50 - Loss: 2.416587
[2025-05-10 22:28:46] Batch 55 - Loss: 2.405870
[2025-05-10 22:28:48] Batch 60 - Loss: 2.418269
[2025-05-10 22:28:49] Batch 65 - Loss: 2.413666
[2025-05-10 22:28:51] Batch 70 - Loss: 2.392581
[2025-05-10 22:28:53] Batch 75 - Loss: 2.391739
[2025-05-10 22:28:55] Batch 80 - Loss: 2.398803
[2025-05-10 22:28:57] Batch 85 - Loss: 2.388539
[2025-05-10 22:28:59] Batch 90 - Loss: 2.371834
[2025-05-10 22:29:00] Batch 95 - Loss: 2.374486
[2025-05-10 22:29:08] === Epoch 22/50 Summary ===
Training Loss: 2.373346
Validation Loss: 5.100387
Learning Rate: 0.00003000
[2025-05-10 22:29:08] Batch 0 - Loss: 1.865911
[2025-05-10 22:29:10] Batch 5 - Loss: 2.148744
[2025-05-10 22:29:11] Batch 10 - Loss: 2.151459
[2025-05-10 22:29:13] Batch 15 - Loss: 2.364670
[2025-05-10 22:29:15] Batch 20 - Loss: 2.408785
[2025-05-10 22:29:17] Batch 25 - Loss: 2.421967
[2025-05-10 22:29:18] Batch 30 - Loss: 2.376925
[2025-05-10 22:29:20] Batch 35 - Loss: 2.373104
[2025-05-10 22:29:22] Batch 40 - Loss: 2.366732
[2025-05-10 22:29:23] Batch 45 - Loss: 2.348946
[2025-05-10 22:29:25] Batch 50 - Loss: 2.321451
[2025-05-10 22:29:27] Batch 55 - Loss: 2.329495
[2025-05-10 22:29:29] Batch 60 - Loss: 2.316708
[2025-05-10 22:29:30] Batch 65 - Loss: 2.313040
[2025-05-10 22:29:32] Batch 70 - Loss: 2.320219
[2025-05-10 22:29:34] Batch 75 - Loss: 2.308457
[2025-05-10 22:29:35] Batch 80 - Loss: 2.309595
[2025-05-10 22:29:37] Batch 85 - Loss: 2.307117
[2025-05-10 22:29:39] Batch 90 - Loss: 2.311754
[2025-05-10 22:29:41] Batch 95 - Loss: 2.296322
[2025-05-10 22:29:48] === Epoch 23/50 Summary ===
Training Loss: 2.285138
Validation Loss: 5.071212
Learning Rate: 0.00003000
[2025-05-10 22:29:48] Batch 0 - Loss: 2.294120
[2025-05-10 22:29:50] Batch 5 - Loss: 2.300379
[2025-05-10 22:29:52] Batch 10 - Loss: 2.200391
[2025-05-10 22:29:53] Batch 15 - Loss: 2.230131
[2025-05-10 22:29:55] Batch 20 - Loss: 2.199942
[2025-05-10 22:29:57] Batch 25 - Loss: 2.200034
[2025-05-10 22:29:58] Batch 30 - Loss: 2.191881
[2025-05-10 22:30:00] Batch 35 - Loss: 2.187112
[2025-05-10 22:30:06] === Epoch 24/50 Summary ===
Training Loss: 2.186070
Validation Loss: 5.040593
Learning Rate: 0.00003000
[2025-05-10 22:30:07] Batch 0 - Loss: 2.339579
[2025-05-10 22:30:09] Batch 5 - Loss: 2.436467
[2025-05-10 22:30:10] Batch 10 - Loss: 2.421887
[2025-05-10 22:30:12] Batch 15 - Loss: 2.396809
[2025-05-10 22:30:14] Batch 20 - Loss: 2.314134
[2025-05-10 22:30:15] Batch 25 - Loss: 2.284152
[2025-05-10 22:30:17] Batch 30 - Loss: 2.341541
[2025-05-10 22:30:19] Batch 35 - Loss: 2.337217
[2025-05-10 22:30:21] Batch 40 - Loss: 2.328486
[2025-05-10 22:30:22] Batch 45 - Loss: 2.351660
[2025-05-10 22:30:24] Batch 50 - Loss: 2.341608
[2025-05-10 22:30:26] Batch 55 - Loss: 2.345976
[2025-05-10 22:30:27] Batch 60 - Loss: 2.335905
[2025-05-10 22:30:29] Batch 65 - Loss: 2.336813
[2025-05-10 22:30:31] Batch 70 - Loss: 2.335794
[2025-05-10 22:30:33] Batch 75 - Loss: 2.320616
[2025-05-10 22:30:34] Batch 80 - Loss: 2.308889
[2025-05-10 22:30:36] Batch 85 - Loss: 2.293407
[2025-05-10 22:30:38] Batch 90 - Loss: 2.294987
[2025-05-10 22:30:40] Batch 95 - Loss: 2.285544
[2025-05-10 22:30:47] === Epoch 25/50 Summary ===
Training Loss: 2.276387
Validation Loss: 5.057319
Learning Rate: 0.00003000
[2025-05-10 22:30:47] Generating detection visualizations for epoch 25...
[2025-05-10 22:30:47] Saved visualization to trained_models/custom_detector\visualizations\epoch_25\sample_1.png
[2025-05-10 22:30:47] Saved visualization to trained_models/custom_detector\visualizations\epoch_25\sample_2.png
[2025-05-10 22:30:48] Saved visualization to trained_models/custom_detector\visualizations\epoch_25\sample_3.png
[2025-05-10 22:30:48] Batch 0 - Loss: 1.885413
[2025-05-10 22:30:50] Batch 5 - Loss: 2.119478
[2025-05-10 22:30:51] Batch 10 - Loss: 2.096348
[2025-05-10 22:30:53] Batch 15 - Loss: 2.232628
[2025-05-10 22:30:55] Batch 20 - Loss: 2.208894
[2025-05-10 22:30:57] Batch 25 - Loss: 2.211557
[2025-05-10 22:30:58] Batch 30 - Loss: 2.216905
[2025-05-10 22:31:00] Batch 35 - Loss: 2.223846
[2025-05-10 22:31:02] Batch 40 - Loss: 2.226749
[2025-05-10 22:31:03] Batch 45 - Loss: 2.237077
[2025-05-10 22:31:05] Batch 50 - Loss: 2.225360
[2025-05-10 22:31:07] Batch 55 - Loss: 2.214116
[2025-05-10 22:31:09] Batch 60 - Loss: 2.225122
[2025-05-10 22:31:10] Batch 65 - Loss: 2.221961
[2025-05-10 22:31:12] Batch 70 - Loss: 2.228524
[2025-05-10 22:31:14] Batch 75 - Loss: 2.224187
[2025-05-10 22:31:15] Batch 80 - Loss: 2.225976
[2025-05-10 22:31:17] Batch 85 - Loss: 2.226873
[2025-05-10 22:31:19] Batch 90 - Loss: 2.218398
[2025-05-10 22:31:21] Batch 95 - Loss: 2.214221
[2025-05-10 22:31:28] === Epoch 26/50 Summary ===
Training Loss: 2.206972
Validation Loss: 5.060457
Learning Rate: 0.00003000
[2025-05-10 22:31:28] Batch 0 - Loss: 2.456694
[2025-05-10 22:31:30] Batch 5 - Loss: 2.094432
[2025-05-10 22:31:31] Batch 10 - Loss: 2.151207
[2025-05-10 22:31:33] Batch 15 - Loss: 2.121849
[2025-05-10 22:31:35] Batch 20 - Loss: 2.124760
[2025-05-10 22:31:37] Batch 25 - Loss: 2.128695
[2025-05-10 22:31:38] Batch 30 - Loss: 2.114164
[2025-05-10 22:31:40] Batch 35 - Loss: 2.133322
[2025-05-10 22:31:42] Batch 40 - Loss: 2.121624
[2025-05-10 22:31:43] Batch 45 - Loss: 2.102868
[2025-05-10 22:31:45] Batch 50 - Loss: 2.111230
[2025-05-10 22:31:47] Batch 55 - Loss: 2.102868
[2025-05-10 22:31:49] Batch 60 - Loss: 2.114247
[2025-05-10 22:31:50] Batch 65 - Loss: 2.119462
[2025-05-10 22:31:52] Batch 70 - Loss: 2.107399
[2025-05-10 22:31:54] Batch 75 - Loss: 2.089719
[2025-05-10 22:31:55] Batch 80 - Loss: 2.083211
[2025-05-10 22:31:57] Batch 85 - Loss: 2.088288
[2025-05-10 22:31:59] Batch 90 - Loss: 2.081927
[2025-05-10 22:32:01] Batch 95 - Loss: 2.076917
[2025-05-10 22:32:08] === Epoch 27/50 Summary ===
Training Loss: 2.076139
Validation Loss: 5.045137
Learning Rate: 0.00003000
[2025-05-10 22:32:08] Batch 0 - Loss: 1.894481
[2025-05-10 22:32:10] Batch 5 - Loss: 1.888442
[2025-05-10 22:32:12] Batch 10 - Loss: 1.858965
[2025-05-10 22:32:13] Batch 15 - Loss: 1.846619
[2025-05-10 22:32:15] Batch 20 - Loss: 1.910141
[2025-05-10 22:32:17] Batch 25 - Loss: 1.896518
[2025-05-10 22:32:18] Batch 30 - Loss: 1.891228
[2025-05-10 22:32:20] Batch 35 - Loss: 1.935341
[2025-05-10 22:32:26] === Epoch 28/50 Summary ===
Training Loss: 1.932767
Validation Loss: 4.948230
Learning Rate: 0.00003000
[2025-05-10 22:32:27] Batch 0 - Loss: 2.079240
[2025-05-10 22:32:29] Batch 5 - Loss: 2.165169
[2025-05-10 22:32:30] Batch 10 - Loss: 2.183474
[2025-05-10 22:32:32] Batch 15 - Loss: 2.169671
[2025-05-10 22:32:34] Batch 20 - Loss: 2.208915
[2025-05-10 22:32:35] Batch 25 - Loss: 2.229958
[2025-05-10 22:32:37] Batch 30 - Loss: 2.253317
[2025-05-10 22:32:39] Batch 35 - Loss: 2.220259
[2025-05-10 22:32:41] Batch 40 - Loss: 2.207749
[2025-05-10 22:32:42] Batch 45 - Loss: 2.207635
[2025-05-10 22:32:44] Batch 50 - Loss: 2.181038
[2025-05-10 22:32:46] Batch 55 - Loss: 2.168692
[2025-05-10 22:32:48] Batch 60 - Loss: 2.163520
[2025-05-10 22:32:49] Batch 65 - Loss: 2.168027
[2025-05-10 22:32:51] Batch 70 - Loss: 2.153011
[2025-05-10 22:32:53] Batch 75 - Loss: 2.148090
[2025-05-10 22:32:54] Batch 80 - Loss: 2.133706
[2025-05-10 22:32:56] Batch 85 - Loss: 2.119933
[2025-05-10 22:32:58] Batch 90 - Loss: 2.103056
[2025-05-10 22:33:00] Batch 95 - Loss: 2.089732
[2025-05-10 22:33:07] === Epoch 29/50 Summary ===
Training Loss: 2.081379
Validation Loss: 5.038976
Learning Rate: 0.00003000
[2025-05-10 22:33:07] Batch 0 - Loss: 1.875259
[2025-05-10 22:33:09] Batch 5 - Loss: 1.970169
[2025-05-10 22:33:10] Batch 10 - Loss: 2.035518
[2025-05-10 22:33:12] Batch 15 - Loss: 2.021567
[2025-05-10 22:33:14] Batch 20 - Loss: 1.998400
[2025-05-10 22:33:16] Batch 25 - Loss: 1.966877
[2025-05-10 22:33:17] Batch 30 - Loss: 1.968264
[2025-05-10 22:33:19] Batch 35 - Loss: 1.964741
[2025-05-10 22:33:21] Batch 40 - Loss: 1.982441
[2025-05-10 22:33:22] Batch 45 - Loss: 1.980709
[2025-05-10 22:33:24] Batch 50 - Loss: 2.018308
[2025-05-10 22:33:26] Batch 55 - Loss: 2.033808
[2025-05-10 22:33:28] Batch 60 - Loss: 2.044252
[2025-05-10 22:33:30] Batch 65 - Loss: 2.033661
[2025-05-10 22:33:31] Batch 70 - Loss: 2.048051
[2025-05-10 22:33:33] Batch 75 - Loss: 2.042406
[2025-05-10 22:33:35] Batch 80 - Loss: 2.019853
[2025-05-10 22:33:37] Batch 85 - Loss: 2.018638
[2025-05-10 22:33:38] Batch 90 - Loss: 2.025461
[2025-05-10 22:33:40] Batch 95 - Loss: 2.018968
[2025-05-10 22:33:47] === Epoch 30/50 Summary ===
Training Loss: 2.006540
Validation Loss: 4.929679
Learning Rate: 0.00003000
[2025-05-10 22:33:47] Generating detection visualizations for epoch 30...
[2025-05-10 22:33:48] Saved visualization to trained_models/custom_detector\visualizations\epoch_30\sample_1.png
[2025-05-10 22:33:48] Saved visualization to trained_models/custom_detector\visualizations\epoch_30\sample_2.png
[2025-05-10 22:33:48] Saved visualization to trained_models/custom_detector\visualizations\epoch_30\sample_3.png
[2025-05-10 22:33:49] Batch 0 - Loss: 1.673759
[2025-05-10 22:33:50] Batch 5 - Loss: 1.882457
[2025-05-10 22:33:52] Batch 10 - Loss: 1.876053
[2025-05-10 22:33:54] Batch 15 - Loss: 2.002864
[2025-05-10 22:33:56] Batch 20 - Loss: 2.013366
[2025-05-10 22:33:57] Batch 25 - Loss: 1.984328
[2025-05-10 22:33:59] Batch 30 - Loss: 1.961647
[2025-05-10 22:34:01] Batch 35 - Loss: 1.968683
[2025-05-10 22:34:03] Batch 40 - Loss: 1.942677
[2025-05-10 22:34:04] Batch 45 - Loss: 1.950365
[2025-05-10 22:34:06] Batch 50 - Loss: 1.931826
[2025-05-10 22:34:08] Batch 55 - Loss: 1.938166
[2025-05-10 22:34:10] Batch 60 - Loss: 1.939526
[2025-05-10 22:34:12] Batch 65 - Loss: 1.948615
[2025-05-10 22:34:14] Batch 70 - Loss: 1.936079
[2025-05-10 22:34:16] Batch 75 - Loss: 1.921018
[2025-05-10 22:34:17] Batch 80 - Loss: 1.921104
[2025-05-10 22:34:19] Batch 85 - Loss: 1.906262
[2025-05-10 22:34:21] Batch 90 - Loss: 1.892104
[2025-05-10 22:34:22] Batch 95 - Loss: 1.890715
[2025-05-10 22:34:29] === Epoch 31/50 Summary ===
Training Loss: 1.890408
Validation Loss: 4.947515
Learning Rate: 0.00003000
[2025-05-10 22:34:30] Batch 0 - Loss: 1.532050
[2025-05-10 22:34:31] Batch 5 - Loss: 1.800925
[2025-05-10 22:34:33] Batch 10 - Loss: 1.807906
[2025-05-10 22:34:35] Batch 15 - Loss: 1.789329
[2025-05-10 22:34:37] Batch 20 - Loss: 1.782112
[2025-05-10 22:34:38] Batch 25 - Loss: 1.792081
[2025-05-10 22:34:40] Batch 30 - Loss: 1.783469
[2025-05-10 22:34:42] Batch 35 - Loss: 1.765288
[2025-05-10 22:34:48] === Epoch 32/50 Summary ===
Training Loss: 1.771727
Validation Loss: 5.046572
Learning Rate: 0.00003000
[2025-05-10 22:34:48] Batch 0 - Loss: 1.593810
[2025-05-10 22:34:50] Batch 5 - Loss: 1.987781
[2025-05-10 22:34:52] Batch 10 - Loss: 2.054354
[2025-05-10 22:34:53] Batch 15 - Loss: 1.983444
[2025-05-10 22:34:55] Batch 20 - Loss: 1.951618
[2025-05-10 22:34:57] Batch 25 - Loss: 1.978316
[2025-05-10 22:34:59] Batch 30 - Loss: 1.963966
[2025-05-10 22:35:00] Batch 35 - Loss: 1.961538
[2025-05-10 22:35:02] Batch 40 - Loss: 1.978451
[2025-05-10 22:35:04] Batch 45 - Loss: 1.988866
[2025-05-10 22:35:06] Batch 50 - Loss: 1.977574
[2025-05-10 22:35:07] Batch 55 - Loss: 1.974873
[2025-05-10 22:35:09] Batch 60 - Loss: 1.972915
[2025-05-10 22:35:11] Batch 65 - Loss: 1.960995
[2025-05-10 22:35:13] Batch 70 - Loss: 1.962634
[2025-05-10 22:35:14] Batch 75 - Loss: 1.955185
[2025-05-10 22:35:16] Batch 80 - Loss: 1.962940
[2025-05-10 22:35:18] Batch 85 - Loss: 1.952130
[2025-05-10 22:35:20] Batch 90 - Loss: 1.943519
[2025-05-10 22:35:21] Batch 95 - Loss: 1.935887
[2025-05-10 22:35:29] === Epoch 33/50 Summary ===
Training Loss: 1.932284
Validation Loss: 4.968802
Learning Rate: 0.00003000
[2025-05-10 22:35:29] Batch 0 - Loss: 1.987859
[2025-05-10 22:35:31] Batch 5 - Loss: 1.802005
[2025-05-10 22:35:33] Batch 10 - Loss: 1.789287
[2025-05-10 22:35:35] Batch 15 - Loss: 1.787066
[2025-05-10 22:35:36] Batch 20 - Loss: 1.831622
[2025-05-10 22:35:38] Batch 25 - Loss: 1.870054
[2025-05-10 22:35:40] Batch 30 - Loss: 1.827978
[2025-05-10 22:35:42] Batch 35 - Loss: 1.829875
[2025-05-10 22:35:44] Batch 40 - Loss: 1.825981
[2025-05-10 22:35:45] Batch 45 - Loss: 1.816015
[2025-05-10 22:35:47] Batch 50 - Loss: 1.831151
[2025-05-10 22:35:49] Batch 55 - Loss: 1.837641
[2025-05-10 22:35:51] Batch 60 - Loss: 1.844144
[2025-05-10 22:35:53] Batch 65 - Loss: 1.839115
[2025-05-10 22:35:54] Batch 70 - Loss: 1.831699
[2025-05-10 22:35:56] Batch 75 - Loss: 1.835892
[2025-05-10 22:35:58] Batch 80 - Loss: 1.840427
[2025-05-10 22:36:00] Batch 85 - Loss: 1.838929
[2025-05-10 22:36:02] Batch 90 - Loss: 1.837661
[2025-05-10 22:36:03] Batch 95 - Loss: 1.833522
[2025-05-10 22:36:11] === Epoch 34/50 Summary ===
Training Loss: 1.835807
Validation Loss: 4.951697
Learning Rate: 0.00003000
[2025-05-10 22:36:11] Batch 0 - Loss: 1.691721
[2025-05-10 22:36:13] Batch 5 - Loss: 1.925739
[2025-05-10 22:36:14] Batch 10 - Loss: 1.890822
[2025-05-10 22:36:16] Batch 15 - Loss: 1.889053
[2025-05-10 22:36:18] Batch 20 - Loss: 1.857684
[2025-05-10 22:36:20] Batch 25 - Loss: 1.819794
[2025-05-10 22:36:22] Batch 30 - Loss: 1.820811
[2025-05-10 22:36:23] Batch 35 - Loss: 1.820039
[2025-05-10 22:36:25] Batch 40 - Loss: 1.779370
[2025-05-10 22:36:27] Batch 45 - Loss: 1.769517
[2025-05-10 22:36:29] Batch 50 - Loss: 1.780189
[2025-05-10 22:36:31] Batch 55 - Loss: 1.775851
[2025-05-10 22:36:32] Batch 60 - Loss: 1.773661
[2025-05-10 22:36:34] Batch 65 - Loss: 1.768440
[2025-05-10 22:36:36] Batch 70 - Loss: 1.769601
[2025-05-10 22:36:38] Batch 75 - Loss: 1.761446
[2025-05-10 22:36:40] Batch 80 - Loss: 1.751836
[2025-05-10 22:36:42] Batch 85 - Loss: 1.743124
[2025-05-10 22:36:43] Batch 90 - Loss: 1.747087
[2025-05-10 22:36:45] Batch 95 - Loss: 1.745953
[2025-05-10 22:36:53] === Epoch 35/50 Summary ===
Training Loss: 1.743080
Validation Loss: 4.899912
Learning Rate: 0.00003000
[2025-05-10 22:36:53] Generating detection visualizations for epoch 35...
[2025-05-10 22:36:54] Saved visualization to trained_models/custom_detector\visualizations\epoch_35\sample_1.png
[2025-05-10 22:36:54] Saved visualization to trained_models/custom_detector\visualizations\epoch_35\sample_2.png
[2025-05-10 22:36:54] Saved visualization to trained_models/custom_detector\visualizations\epoch_35\sample_3.png
[2025-05-10 22:36:55] Batch 0 - Loss: 1.849497
[2025-05-10 22:36:57] Batch 5 - Loss: 1.807739
[2025-05-10 22:36:58] Batch 10 - Loss: 1.769126
[2025-05-10 22:37:00] Batch 15 - Loss: 1.682483
[2025-05-10 22:37:02] Batch 20 - Loss: 1.709672
[2025-05-10 22:37:04] Batch 25 - Loss: 1.681831
[2025-05-10 22:37:06] Batch 30 - Loss: 1.738106
[2025-05-10 22:37:07] Batch 35 - Loss: 1.718596
[2025-05-10 22:37:14] === Epoch 36/50 Summary ===
Training Loss: 1.716708
Validation Loss: 4.875889
Learning Rate: 0.00003000
[2025-05-10 22:37:14] Batch 0 - Loss: 1.561765
[2025-05-10 22:37:16] Batch 5 - Loss: 1.715091
[2025-05-10 22:37:18] Batch 10 - Loss: 1.889694
[2025-05-10 22:37:20] Batch 15 - Loss: 1.966199
[2025-05-10 22:37:22] Batch 20 - Loss: 1.890129
[2025-05-10 22:37:23] Batch 25 - Loss: 1.940439
[2025-05-10 22:37:25] Batch 30 - Loss: 1.901253
[2025-05-10 22:37:27] Batch 35 - Loss: 1.886265
[2025-05-10 22:37:29] Batch 40 - Loss: 1.868286
[2025-05-10 22:37:31] Batch 45 - Loss: 1.871946
[2025-05-10 22:37:32] Batch 50 - Loss: 1.861337
[2025-05-10 22:37:34] Batch 55 - Loss: 1.840170
[2025-05-10 22:37:36] Batch 60 - Loss: 1.839798
[2025-05-10 22:37:38] Batch 65 - Loss: 1.843592
[2025-05-10 22:37:39] Batch 70 - Loss: 1.827742
[2025-05-10 22:37:41] Batch 75 - Loss: 1.819730
[2025-05-10 22:37:43] Batch 80 - Loss: 1.805713
[2025-05-10 22:37:45] Batch 85 - Loss: 1.797894
[2025-05-10 22:37:46] Batch 90 - Loss: 1.800079
[2025-05-10 22:37:48] Batch 95 - Loss: 1.796821
[2025-05-10 22:37:55] === Epoch 37/50 Summary ===
Training Loss: 1.792859
Validation Loss: 5.002332
Learning Rate: 0.00003000
[2025-05-10 22:37:56] Batch 0 - Loss: 1.792330
[2025-05-10 22:37:58] Batch 5 - Loss: 1.775072
[2025-05-10 22:37:59] Batch 10 - Loss: 1.677300
[2025-05-10 22:38:01] Batch 15 - Loss: 1.698362
[2025-05-10 22:38:03] Batch 20 - Loss: 1.676058
[2025-05-10 22:38:05] Batch 25 - Loss: 1.694814
[2025-05-10 22:38:07] Batch 30 - Loss: 1.721438
[2025-05-10 22:38:08] Batch 35 - Loss: 1.717804
[2025-05-10 22:38:10] Batch 40 - Loss: 1.700243
[2025-05-10 22:38:12] Batch 45 - Loss: 1.693938
[2025-05-10 22:38:14] Batch 50 - Loss: 1.705740
[2025-05-10 22:38:15] Batch 55 - Loss: 1.700618
[2025-05-10 22:38:17] Batch 60 - Loss: 1.713247
[2025-05-10 22:38:19] Batch 65 - Loss: 1.710750
[2025-05-10 22:38:21] Batch 70 - Loss: 1.700927
[2025-05-10 22:38:22] Batch 75 - Loss: 1.687496
[2025-05-10 22:38:24] Batch 80 - Loss: 1.687088
[2025-05-10 22:38:26] Batch 85 - Loss: 1.684977
[2025-05-10 22:38:28] Batch 90 - Loss: 1.687371
[2025-05-10 22:38:30] Batch 95 - Loss: 1.688544
[2025-05-10 22:38:38] === Epoch 38/50 Summary ===
Training Loss: 1.692348
Validation Loss: 4.859447
Learning Rate: 0.00003000
[2025-05-10 22:38:38] Batch 0 - Loss: 1.676241
[2025-05-10 22:38:40] Batch 5 - Loss: 1.698869
[2025-05-10 22:38:42] Batch 10 - Loss: 1.752428
[2025-05-10 22:38:44] Batch 15 - Loss: 1.760024
[2025-05-10 22:38:46] Batch 20 - Loss: 1.701741
[2025-05-10 22:38:48] Batch 25 - Loss: 1.670666
[2025-05-10 22:38:50] Batch 30 - Loss: 1.678933
[2025-05-10 22:38:52] Batch 35 - Loss: 1.687959
[2025-05-10 22:38:54] Batch 40 - Loss: 1.677394
[2025-05-10 22:38:56] Batch 45 - Loss: 1.663098
[2025-05-10 22:38:57] Batch 50 - Loss: 1.663536
[2025-05-10 22:38:59] Batch 55 - Loss: 1.681030
[2025-05-10 22:39:01] Batch 60 - Loss: 1.679903
[2025-05-10 22:39:03] Batch 65 - Loss: 1.662416
[2025-05-10 22:39:05] Batch 70 - Loss: 1.653970
[2025-05-10 22:39:07] Batch 75 - Loss: 1.643293
[2025-05-10 22:39:08] Batch 80 - Loss: 1.629560
[2025-05-10 22:39:10] Batch 85 - Loss: 1.630141
[2025-05-10 22:39:12] Batch 90 - Loss: 1.630921
[2025-05-10 22:39:14] Batch 95 - Loss: 1.639260
[2025-05-10 22:39:21] === Epoch 39/50 Summary ===
Training Loss: 1.629773
Validation Loss: 4.940567
Learning Rate: 0.00003000
[2025-05-10 22:39:21] Batch 0 - Loss: 1.436152
[2025-05-10 22:39:23] Batch 5 - Loss: 1.435556
[2025-05-10 22:39:25] Batch 10 - Loss: 1.490365
[2025-05-10 22:39:27] Batch 15 - Loss: 1.511199
[2025-05-10 22:39:28] Batch 20 - Loss: 1.489417
[2025-05-10 22:39:30] Batch 25 - Loss: 1.500638
[2025-05-10 22:39:32] Batch 30 - Loss: 1.518417
[2025-05-10 22:39:34] Batch 35 - Loss: 1.523242
[2025-05-10 22:39:40] === Epoch 40/50 Summary ===
Training Loss: 1.524323
Validation Loss: 4.868994
Learning Rate: 0.00003000
[2025-05-10 22:39:40] Generating detection visualizations for epoch 40...
[2025-05-10 22:39:40] Saved visualization to trained_models/custom_detector\visualizations\epoch_40\sample_1.png
[2025-05-10 22:39:41] Saved visualization to trained_models/custom_detector\visualizations\epoch_40\sample_2.png
[2025-05-10 22:39:41] Saved visualization to trained_models/custom_detector\visualizations\epoch_40\sample_3.png
[2025-05-10 22:39:42] Batch 0 - Loss: 1.796201
[2025-05-10 22:39:43] Batch 5 - Loss: 1.695385
[2025-05-10 22:39:45] Batch 10 - Loss: 1.673917
[2025-05-10 22:39:47] Batch 15 - Loss: 1.770652
[2025-05-10 22:39:49] Batch 20 - Loss: 1.761073
[2025-05-10 22:39:51] Batch 25 - Loss: 1.747013
[2025-05-10 22:39:52] Batch 30 - Loss: 1.736630
[2025-05-10 22:39:54] Batch 35 - Loss: 1.743305
[2025-05-10 22:39:56] Batch 40 - Loss: 1.728145
[2025-05-10 22:39:58] Batch 45 - Loss: 1.739745
[2025-05-10 22:39:59] Batch 50 - Loss: 1.731035
[2025-05-10 22:40:01] Batch 55 - Loss: 1.731623
[2025-05-10 22:40:03] Batch 60 - Loss: 1.728743
[2025-05-10 22:40:05] Batch 65 - Loss: 1.717153
[2025-05-10 22:40:06] Batch 70 - Loss: 1.703357
[2025-05-10 22:40:08] Batch 75 - Loss: 1.680025
[2025-05-10 22:40:10] Batch 80 - Loss: 1.678850
[2025-05-10 22:40:12] Batch 85 - Loss: 1.680321
[2025-05-10 22:40:14] Batch 90 - Loss: 1.679235
[2025-05-10 22:40:15] Batch 95 - Loss: 1.664931
[2025-05-10 22:40:23] === Epoch 41/50 Summary ===
Training Loss: 1.660241
Validation Loss: 4.953161
Learning Rate: 0.00003000
[2025-05-10 22:40:23] Batch 0 - Loss: 1.510632
[2025-05-10 22:40:25] Batch 5 - Loss: 1.468310
[2025-05-10 22:40:27] Batch 10 - Loss: 1.513185
[2025-05-10 22:40:28] Batch 15 - Loss: 1.574959
[2025-05-10 22:40:30] Batch 20 - Loss: 1.575715
[2025-05-10 22:40:32] Batch 25 - Loss: 1.592368
[2025-05-10 22:40:34] Batch 30 - Loss: 1.565742
[2025-05-10 22:40:36] Batch 35 - Loss: 1.578810
[2025-05-10 22:40:37] Batch 40 - Loss: 1.578399
[2025-05-10 22:40:39] Batch 45 - Loss: 1.560566
[2025-05-10 22:40:41] Batch 50 - Loss: 1.550207
[2025-05-10 22:40:43] Batch 55 - Loss: 1.549462
[2025-05-10 22:40:44] Batch 60 - Loss: 1.561190
[2025-05-10 22:40:46] Batch 65 - Loss: 1.572987
[2025-05-10 22:40:48] Batch 70 - Loss: 1.578576
[2025-05-10 22:40:50] Batch 75 - Loss: 1.584587
[2025-05-10 22:40:51] Batch 80 - Loss: 1.580840
[2025-05-10 22:40:53] Batch 85 - Loss: 1.587171
[2025-05-10 22:40:55] Batch 90 - Loss: 1.584324
[2025-05-10 22:40:57] Batch 95 - Loss: 1.583813
[2025-05-10 22:41:04] === Epoch 42/50 Summary ===
Training Loss: 1.585185
Validation Loss: 4.889886
Learning Rate: 0.00003000
[2025-05-10 22:41:05] Batch 0 - Loss: 1.623139
[2025-05-10 22:41:06] Batch 5 - Loss: 1.596012
[2025-05-10 22:41:08] Batch 10 - Loss: 1.539223
[2025-05-10 22:41:10] Batch 15 - Loss: 1.551717
[2025-05-10 22:41:12] Batch 20 - Loss: 1.542397
[2025-05-10 22:41:13] Batch 25 - Loss: 1.521646
[2025-05-10 22:41:15] Batch 30 - Loss: 1.536437
[2025-05-10 22:41:17] Batch 35 - Loss: 1.534051
[2025-05-10 22:41:19] Batch 40 - Loss: 1.531287
[2025-05-10 22:41:21] Batch 45 - Loss: 1.529187
[2025-05-10 22:41:22] Batch 50 - Loss: 1.521192
[2025-05-10 22:41:24] Batch 55 - Loss: 1.559293
[2025-05-10 22:41:26] Batch 60 - Loss: 1.554505
[2025-05-10 22:41:28] Batch 65 - Loss: 1.554631
[2025-05-10 22:41:29] Batch 70 - Loss: 1.538387
[2025-05-10 22:41:31] Batch 75 - Loss: 1.534192
[2025-05-10 22:41:33] Batch 80 - Loss: 1.519268
[2025-05-10 22:41:35] Batch 85 - Loss: 1.515741
[2025-05-10 22:41:36] Batch 90 - Loss: 1.507685
[2025-05-10 22:41:38] Batch 95 - Loss: 1.505802
[2025-05-10 22:41:46] === Epoch 43/50 Summary ===
Training Loss: 1.503865
Validation Loss: 4.894816
Learning Rate: 0.00000600
[2025-05-10 22:41:46] Batch 0 - Loss: 1.302789
[2025-05-10 22:41:48] Batch 5 - Loss: 1.435587
[2025-05-10 22:41:49] Batch 10 - Loss: 1.377105
[2025-05-10 22:41:51] Batch 15 - Loss: 1.403813
[2025-05-10 22:41:53] Batch 20 - Loss: 1.395177
[2025-05-10 22:41:55] Batch 25 - Loss: 1.402260
[2025-05-10 22:41:56] Batch 30 - Loss: 1.390560
[2025-05-10 22:41:58] Batch 35 - Loss: 1.419105
[2025-05-10 22:42:04] === Epoch 44/50 Summary ===
Training Loss: 1.412718
Validation Loss: 4.860630
Learning Rate: 0.00000600
[2025-05-10 22:42:05] Batch 0 - Loss: 1.183141
[2025-05-10 22:42:07] Batch 5 - Loss: 1.454585
[2025-05-10 22:42:08] Batch 10 - Loss: 1.546376
[2025-05-10 22:42:10] Batch 15 - Loss: 1.592370
[2025-05-10 22:42:12] Batch 20 - Loss: 1.591586
[2025-05-10 22:42:14] Batch 25 - Loss: 1.613282
[2025-05-10 22:42:16] Batch 30 - Loss: 1.612090
[2025-05-10 22:42:17] Batch 35 - Loss: 1.598491
[2025-05-10 22:42:19] Batch 40 - Loss: 1.574476
[2025-05-10 22:42:21] Batch 45 - Loss: 1.559058
[2025-05-10 22:42:23] Batch 50 - Loss: 1.553541
[2025-05-10 22:42:24] Batch 55 - Loss: 1.550952
[2025-05-10 22:42:26] Batch 60 - Loss: 1.536167
[2025-05-10 22:42:28] Batch 65 - Loss: 1.524003
[2025-05-10 22:42:30] Batch 70 - Loss: 1.518787
[2025-05-10 22:42:32] Batch 75 - Loss: 1.513672
[2025-05-10 22:42:33] Batch 80 - Loss: 1.498049
[2025-05-10 22:42:35] Batch 85 - Loss: 1.497948
[2025-05-10 22:42:37] Batch 90 - Loss: 1.492848
[2025-05-10 22:42:39] Batch 95 - Loss: 1.484611
[2025-05-10 22:42:46] === Epoch 45/50 Summary ===
Training Loss: 1.477905
Validation Loss: 4.887467
Learning Rate: 0.00000600
[2025-05-10 22:42:46] Generating detection visualizations for epoch 45...
[2025-05-10 22:42:46] Saved visualization to trained_models/custom_detector\visualizations\epoch_45\sample_1.png
[2025-05-10 22:42:47] Saved visualization to trained_models/custom_detector\visualizations\epoch_45\sample_2.png
[2025-05-10 22:42:47] Saved visualization to trained_models/custom_detector\visualizations\epoch_45\sample_3.png
[2025-05-10 22:42:47] Batch 0 - Loss: 1.384730
[2025-05-10 22:42:49] Batch 5 - Loss: 1.434226
[2025-05-10 22:42:51] Batch 10 - Loss: 1.506423
[2025-05-10 22:42:53] Batch 15 - Loss: 1.452303
[2025-05-10 22:42:54] Batch 20 - Loss: 1.452102
[2025-05-10 22:42:56] Batch 25 - Loss: 1.438470
[2025-05-10 22:42:58] Batch 30 - Loss: 1.428264
[2025-05-10 22:43:00] Batch 35 - Loss: 1.421355
[2025-05-10 22:43:02] Batch 40 - Loss: 1.411539
[2025-05-10 22:43:03] Batch 45 - Loss: 1.416912
[2025-05-10 22:43:05] Batch 50 - Loss: 1.412338
[2025-05-10 22:43:07] Batch 55 - Loss: 1.440545
[2025-05-10 22:43:09] Batch 60 - Loss: 1.445736
[2025-05-10 22:43:11] Batch 65 - Loss: 1.437627
[2025-05-10 22:43:12] Batch 70 - Loss: 1.434670
[2025-05-10 22:43:14] Batch 75 - Loss: 1.431369
[2025-05-10 22:43:16] Batch 80 - Loss: 1.422916
[2025-05-10 22:43:18] Batch 85 - Loss: 1.420889
[2025-05-10 22:43:20] Batch 90 - Loss: 1.418480
[2025-05-10 22:43:21] Batch 95 - Loss: 1.425285
[2025-05-10 22:43:29] === Epoch 46/50 Summary ===
Training Loss: 1.425596
Validation Loss: 4.792857
Learning Rate: 0.00000600
[2025-05-10 22:43:29] Batch 0 - Loss: 1.371786
[2025-05-10 22:43:31] Batch 5 - Loss: 1.370142
[2025-05-10 22:43:33] Batch 10 - Loss: 1.376740
[2025-05-10 22:43:34] Batch 15 - Loss: 1.361204
[2025-05-10 22:43:36] Batch 20 - Loss: 1.376965
[2025-05-10 22:43:38] Batch 25 - Loss: 1.359479
[2025-05-10 22:43:39] Batch 30 - Loss: 1.401458
[2025-05-10 22:43:41] Batch 35 - Loss: 1.367679
[2025-05-10 22:43:43] Batch 40 - Loss: 1.365617
[2025-05-10 22:43:45] Batch 45 - Loss: 1.349119
[2025-05-10 22:43:46] Batch 50 - Loss: 1.347989
[2025-05-10 22:43:48] Batch 55 - Loss: 1.368881
[2025-05-10 22:43:50] Batch 60 - Loss: 1.357886
[2025-05-10 22:43:52] Batch 65 - Loss: 1.355445
[2025-05-10 22:43:53] Batch 70 - Loss: 1.360220
[2025-05-10 22:43:55] Batch 75 - Loss: 1.356492
[2025-05-10 22:43:57] Batch 80 - Loss: 1.357407
[2025-05-10 22:43:59] Batch 85 - Loss: 1.365585
[2025-05-10 22:44:00] Batch 90 - Loss: 1.364706
[2025-05-10 22:44:02] Batch 95 - Loss: 1.359468
[2025-05-10 22:44:09] === Epoch 47/50 Summary ===
Training Loss: 1.359469
Validation Loss: 4.814323
Learning Rate: 0.00000600
[2025-05-10 22:44:09] Batch 0 - Loss: 1.307443
[2025-05-10 22:44:11] Batch 5 - Loss: 1.254957
[2025-05-10 22:44:13] Batch 10 - Loss: 1.285726
[2025-05-10 22:44:15] Batch 15 - Loss: 1.281526
[2025-05-10 22:44:16] Batch 20 - Loss: 1.287069
[2025-05-10 22:44:18] Batch 25 - Loss: 1.259482
[2025-05-10 22:44:20] Batch 30 - Loss: 1.268850
[2025-05-10 22:44:21] Batch 35 - Loss: 1.265111
[2025-05-10 22:44:27] === Epoch 48/50 Summary ===
Training Loss: 1.260162
Validation Loss: 4.827206
Learning Rate: 0.00000600
[2025-05-10 22:44:28] Batch 0 - Loss: 1.582892
[2025-05-10 22:44:30] Batch 5 - Loss: 1.562338
[2025-05-10 22:44:31] Batch 10 - Loss: 1.546668
[2025-05-10 22:44:33] Batch 15 - Loss: 1.530876
[2025-05-10 22:44:35] Batch 20 - Loss: 1.486371
[2025-05-10 22:44:37] Batch 25 - Loss: 1.480064
[2025-05-10 22:44:38] Batch 30 - Loss: 1.508117
[2025-05-10 22:44:40] Batch 35 - Loss: 1.517533
[2025-05-10 22:44:42] Batch 40 - Loss: 1.508688
[2025-05-10 22:44:43] Batch 45 - Loss: 1.505355
[2025-05-10 22:44:45] Batch 50 - Loss: 1.487881
[2025-05-10 22:44:47] Batch 55 - Loss: 1.478737
[2025-05-10 22:44:49] Batch 60 - Loss: 1.474346
[2025-05-10 22:44:50] Batch 65 - Loss: 1.469650
[2025-05-10 22:44:52] Batch 70 - Loss: 1.465480
[2025-05-10 22:44:54] Batch 75 - Loss: 1.449185
[2025-05-10 22:44:56] Batch 80 - Loss: 1.448485
[2025-05-10 22:44:57] Batch 85 - Loss: 1.444767
[2025-05-10 22:44:59] Batch 90 - Loss: 1.433731
[2025-05-10 22:45:01] Batch 95 - Loss: 1.431183
[2025-05-10 22:45:08] === Epoch 49/50 Summary ===
Training Loss: 1.422416
Validation Loss: 4.857823
Learning Rate: 0.00000600
[2025-05-10 22:45:08] Batch 0 - Loss: 1.231757
[2025-05-10 22:45:10] Batch 5 - Loss: 1.271680
[2025-05-10 22:45:12] Batch 10 - Loss: 1.346868
[2025-05-10 22:45:13] Batch 15 - Loss: 1.370732
[2025-05-10 22:45:15] Batch 20 - Loss: 1.346459
[2025-05-10 22:45:17] Batch 25 - Loss: 1.344278
[2025-05-10 22:45:18] Batch 30 - Loss: 1.342488
[2025-05-10 22:45:20] Batch 35 - Loss: 1.336187
[2025-05-10 22:45:22] Batch 40 - Loss: 1.347357
[2025-05-10 22:45:24] Batch 45 - Loss: 1.345569
[2025-05-10 22:45:25] Batch 50 - Loss: 1.360884
[2025-05-10 22:45:27] Batch 55 - Loss: 1.362636
[2025-05-10 22:45:29] Batch 60 - Loss: 1.356306
[2025-05-10 22:45:30] Batch 65 - Loss: 1.357237
[2025-05-10 22:45:32] Batch 70 - Loss: 1.352784
[2025-05-10 22:45:34] Batch 75 - Loss: 1.359910
[2025-05-10 22:45:36] Batch 80 - Loss: 1.354486
[2025-05-10 22:45:37] Batch 85 - Loss: 1.361721
[2025-05-10 22:45:39] Batch 90 - Loss: 1.357229
[2025-05-10 22:45:41] Batch 95 - Loss: 1.358886
[2025-05-10 22:45:48] === Epoch 50/50 Summary ===
Training Loss: 1.361858
Validation Loss: 4.796796
Learning Rate: 0.00000600
[2025-05-10 22:45:48] Generating detection visualizations for epoch 50...
[2025-05-10 22:45:48] Saved visualization to trained_models/custom_detector\visualizations\epoch_50\sample_1.png
[2025-05-10 22:45:49] Saved visualization to trained_models/custom_detector\visualizations\epoch_50\sample_2.png
[2025-05-10 22:45:49] Saved visualization to trained_models/custom_detector\visualizations\epoch_50\sample_3.png
[2025-05-10 22:45:49] === Training Completed ===
[2025-05-10 22:45:49] Best epoch: 46
[2025-05-10 22:45:49] Best validation loss: 4.792857
[2025-05-10 22:45:49] Model training completed in 29.92 minutes
[2025-05-10 22:45:49] Model saved to trained_models/custom_detector\final_model.keras
[2025-05-10 22:45:49] Training history plot saved to trained_models/custom_detector\training_history.png
[2025-05-10 22:45:49] === Valorant Detector Completed ===
