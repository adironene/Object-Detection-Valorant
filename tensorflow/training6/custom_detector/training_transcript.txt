[2025-05-10 23:04:32] Starting training session
Model configuration: IMAGE_SIZE=(416, 416), BATCH_SIZE=16, EPOCHS=50, LEARNING_RATE=0.0001

[2025-05-10 23:04:32] === Starting Valorany Detector ===
[2025-05-10 23:04:32] Training data: ../tf_files/train.record
[2025-05-10 23:04:32] Validation data: ../tf_files/valid.record
[2025-05-10 23:04:32] Loading data from ../tf_files/train.record and ../tf_files/valid.record
[2025-05-10 23:04:33] Estimating dataset sizes...
[2025-05-10 23:04:33] Train dataset size: ~337 batches (approx. 5385 examples)
[2025-05-10 23:04:33] Validation dataset size: ~33 batches (approx. 514 examples)
[2025-05-10 23:04:33] Creating model...
[2025-05-10 23:04:33] Starting model training...
[2025-05-10 23:04:34] === Training Started ===
[2025-05-10 23:04:34] Model structure:
[2025-05-10 23:04:34] Total layers: 160
[2025-05-10 23:04:34] Total parameters: 9,344,081
[2025-05-10 23:04:34] Trainable parameters: 7,084,561
[2025-05-10 23:04:34] Non-trainable parameters: 2,259,520
[2025-05-10 23:04:37] Batch 0 - Loss: 550.905151
[2025-05-10 23:04:39] Batch 5 - Loss: 473.201294
[2025-05-10 23:04:41] Batch 10 - Loss: 444.768646
[2025-05-10 23:04:43] Batch 15 - Loss: 415.872223
[2025-05-10 23:04:44] Batch 20 - Loss: 394.618500
[2025-05-10 23:04:46] Batch 25 - Loss: 373.996368
[2025-05-10 23:04:48] Batch 30 - Loss: 357.157562
[2025-05-10 23:04:50] Batch 35 - Loss: 343.633911
[2025-05-10 23:04:52] Batch 40 - Loss: 330.629944
[2025-05-10 23:04:54] Batch 45 - Loss: 317.415710
[2025-05-10 23:04:55] Batch 50 - Loss: 305.505219
[2025-05-10 23:04:57] Batch 55 - Loss: 294.874542
[2025-05-10 23:04:59] Batch 60 - Loss: 284.336517
[2025-05-10 23:05:01] Batch 65 - Loss: 274.018372
[2025-05-10 23:05:03] Batch 70 - Loss: 264.969147
[2025-05-10 23:05:05] Batch 75 - Loss: 255.850693
[2025-05-10 23:05:06] Batch 80 - Loss: 247.104462
[2025-05-10 23:05:08] Batch 85 - Loss: 238.798584
[2025-05-10 23:05:10] Batch 90 - Loss: 230.765823
[2025-05-10 23:05:12] Batch 95 - Loss: 223.049057
[2025-05-10 23:05:19] === Epoch 1/50 Summary ===
Training Loss: 217.247147
Validation Loss: 330.826202
Learning Rate: 0.00003000
[2025-05-10 23:05:20] Batch 0 - Loss: 67.197784
[2025-05-10 23:05:22] Batch 5 - Loss: 69.858498
[2025-05-10 23:05:23] Batch 10 - Loss: 65.329842
[2025-05-10 23:05:25] Batch 15 - Loss: 61.593910
[2025-05-10 23:05:27] Batch 20 - Loss: 59.101631
[2025-05-10 23:05:28] Batch 25 - Loss: 57.009972
[2025-05-10 23:05:30] Batch 30 - Loss: 54.885349
[2025-05-10 23:05:32] Batch 35 - Loss: 52.832809
[2025-05-10 23:05:34] Batch 40 - Loss: 51.288269
[2025-05-10 23:05:36] Batch 45 - Loss: 49.965885
[2025-05-10 23:05:37] Batch 50 - Loss: 48.207279
[2025-05-10 23:05:39] Batch 55 - Loss: 46.266685
[2025-05-10 23:05:41] Batch 60 - Loss: 44.848892
[2025-05-10 23:05:42] Batch 65 - Loss: 43.999966
[2025-05-10 23:05:44] Batch 70 - Loss: 42.544395
[2025-05-10 23:05:46] Batch 75 - Loss: 41.285576
[2025-05-10 23:05:48] Batch 80 - Loss: 40.064896
[2025-05-10 23:05:49] Batch 85 - Loss: 38.830250
[2025-05-10 23:05:51] Batch 90 - Loss: 37.762550
[2025-05-10 23:05:53] Batch 95 - Loss: 36.734303
[2025-05-10 23:06:00] === Epoch 2/50 Summary ===
Training Loss: 35.940098
Validation Loss: 67.857712
Learning Rate: 0.00003000
[2025-05-10 23:06:01] Batch 0 - Loss: 16.895523
[2025-05-10 23:06:02] Batch 5 - Loss: 16.277754
[2025-05-10 23:06:04] Batch 10 - Loss: 16.166027
[2025-05-10 23:06:06] Batch 15 - Loss: 15.916265
[2025-05-10 23:06:08] Batch 20 - Loss: 15.900545
[2025-05-10 23:06:09] Batch 25 - Loss: 15.835684
[2025-05-10 23:06:11] Batch 30 - Loss: 16.195936
[2025-05-10 23:06:13] Batch 35 - Loss: 16.290985
[2025-05-10 23:06:15] Batch 40 - Loss: 15.976406
[2025-05-10 23:06:17] Batch 45 - Loss: 15.835136
[2025-05-10 23:06:18] Batch 50 - Loss: 15.588366
[2025-05-10 23:06:20] Batch 55 - Loss: 15.215189
[2025-05-10 23:06:22] Batch 60 - Loss: 14.965402
[2025-05-10 23:06:24] Batch 65 - Loss: 14.664560
[2025-05-10 23:06:25] Batch 70 - Loss: 14.359532
[2025-05-10 23:06:27] Batch 75 - Loss: 14.163058
[2025-05-10 23:06:29] Batch 80 - Loss: 14.017979
[2025-05-10 23:06:31] Batch 85 - Loss: 13.791057
[2025-05-10 23:06:32] Batch 90 - Loss: 13.593242
[2025-05-10 23:06:34] Batch 95 - Loss: 13.391395
[2025-05-10 23:06:41] === Epoch 3/50 Summary ===
Training Loss: 13.244199
Validation Loss: 26.420231
Learning Rate: 0.00003000
[2025-05-10 23:06:42] Batch 0 - Loss: 10.826319
[2025-05-10 23:06:43] Batch 5 - Loss: 9.743472
[2025-05-10 23:06:45] Batch 10 - Loss: 9.557243
[2025-05-10 23:06:47] Batch 15 - Loss: 10.119835
[2025-05-10 23:06:48] Batch 20 - Loss: 9.827464
[2025-05-10 23:06:50] Batch 25 - Loss: 9.543885
[2025-05-10 23:06:52] Batch 30 - Loss: 9.591061
[2025-05-10 23:06:54] Batch 35 - Loss: 9.446446
[2025-05-10 23:07:00] === Epoch 4/50 Summary ===
Training Loss: 9.426101
Validation Loss: 25.693050
Learning Rate: 0.00003000
[2025-05-10 23:07:01] Batch 0 - Loss: 8.906406
[2025-05-10 23:07:02] Batch 5 - Loss: 9.145366
[2025-05-10 23:07:04] Batch 10 - Loss: 9.530704
[2025-05-10 23:07:06] Batch 15 - Loss: 9.438401
[2025-05-10 23:07:07] Batch 20 - Loss: 9.643213
[2025-05-10 23:07:09] Batch 25 - Loss: 9.592919
[2025-05-10 23:07:11] Batch 30 - Loss: 9.300934
[2025-05-10 23:07:13] Batch 35 - Loss: 9.126752
[2025-05-10 23:07:14] Batch 40 - Loss: 8.994177
[2025-05-10 23:07:16] Batch 45 - Loss: 8.887997
[2025-05-10 23:07:18] Batch 50 - Loss: 8.888896
[2025-05-10 23:07:20] Batch 55 - Loss: 8.836946
[2025-05-10 23:07:21] Batch 60 - Loss: 8.836109
[2025-05-10 23:07:23] Batch 65 - Loss: 8.827961
[2025-05-10 23:07:25] Batch 70 - Loss: 8.759163
[2025-05-10 23:07:26] Batch 75 - Loss: 8.666584
[2025-05-10 23:07:28] Batch 80 - Loss: 8.576826
[2025-05-10 23:07:30] Batch 85 - Loss: 8.494128
[2025-05-10 23:07:32] Batch 90 - Loss: 8.407079
[2025-05-10 23:07:33] Batch 95 - Loss: 8.300040
[2025-05-10 23:07:40] === Epoch 5/50 Summary ===
Training Loss: 8.251341
Validation Loss: 17.512085
Learning Rate: 0.00003000
[2025-05-10 23:07:40] Generating detection visualizations for epoch 5...
[2025-05-10 23:07:41] Saved visualization to trained_models/custom_detector\visualizations\epoch_5\sample_1.png
[2025-05-10 23:07:42] Saved visualization to trained_models/custom_detector\visualizations\epoch_5\sample_2.png
[2025-05-10 23:07:42] Saved visualization to trained_models/custom_detector\visualizations\epoch_5\sample_3.png
[2025-05-10 23:07:42] Batch 0 - Loss: 6.337434
[2025-05-10 23:07:44] Batch 5 - Loss: 7.027082
[2025-05-10 23:07:46] Batch 10 - Loss: 6.610013
[2025-05-10 23:07:48] Batch 15 - Loss: 6.465090
[2025-05-10 23:07:50] Batch 20 - Loss: 6.440972
[2025-05-10 23:07:52] Batch 25 - Loss: 6.528928
[2025-05-10 23:07:54] Batch 30 - Loss: 6.454823
[2025-05-10 23:07:56] Batch 35 - Loss: 6.474235
[2025-05-10 23:07:57] Batch 40 - Loss: 6.467104
[2025-05-10 23:07:59] Batch 45 - Loss: 6.486877
[2025-05-10 23:08:01] Batch 50 - Loss: 6.462346
[2025-05-10 23:08:03] Batch 55 - Loss: 6.621202
[2025-05-10 23:08:04] Batch 60 - Loss: 6.616277
[2025-05-10 23:08:06] Batch 65 - Loss: 6.534775
[2025-05-10 23:08:08] Batch 70 - Loss: 6.523764
[2025-05-10 23:08:10] Batch 75 - Loss: 6.512408
[2025-05-10 23:08:11] Batch 80 - Loss: 6.475833
[2025-05-10 23:08:13] Batch 85 - Loss: 6.447170
[2025-05-10 23:08:15] Batch 90 - Loss: 6.462975
[2025-05-10 23:08:17] Batch 95 - Loss: 6.427713
[2025-05-10 23:08:24] === Epoch 6/50 Summary ===
Training Loss: 6.393819
Validation Loss: 12.077829
Learning Rate: 0.00003000
[2025-05-10 23:08:24] Batch 0 - Loss: 4.783724
[2025-05-10 23:08:26] Batch 5 - Loss: 5.567718
[2025-05-10 23:08:28] Batch 10 - Loss: 5.573709
[2025-05-10 23:08:30] Batch 15 - Loss: 5.616861
[2025-05-10 23:08:31] Batch 20 - Loss: 5.573225
[2025-05-10 23:08:33] Batch 25 - Loss: 5.542784
[2025-05-10 23:08:35] Batch 30 - Loss: 5.648734
[2025-05-10 23:08:37] Batch 35 - Loss: 5.759307
[2025-05-10 23:08:38] Batch 40 - Loss: 5.707716
[2025-05-10 23:08:40] Batch 45 - Loss: 5.737590
[2025-05-10 23:08:42] Batch 50 - Loss: 5.790820
[2025-05-10 23:08:44] Batch 55 - Loss: 5.786358
[2025-05-10 23:08:45] Batch 60 - Loss: 5.806684
[2025-05-10 23:08:47] Batch 65 - Loss: 5.791084
[2025-05-10 23:08:49] Batch 70 - Loss: 5.749698
[2025-05-10 23:08:51] Batch 75 - Loss: 5.734052
[2025-05-10 23:08:52] Batch 80 - Loss: 5.690475
[2025-05-10 23:08:54] Batch 85 - Loss: 5.658216
[2025-05-10 23:08:56] Batch 90 - Loss: 5.633596
[2025-05-10 23:08:57] Batch 95 - Loss: 5.587624
[2025-05-10 23:09:05] === Epoch 7/50 Summary ===
Training Loss: 5.579132
Validation Loss: 9.570372
Learning Rate: 0.00003000
[2025-05-10 23:09:05] Batch 0 - Loss: 5.157158
[2025-05-10 23:09:07] Batch 5 - Loss: 5.229582
[2025-05-10 23:09:09] Batch 10 - Loss: 5.246660
[2025-05-10 23:09:10] Batch 15 - Loss: 5.350944
[2025-05-10 23:09:12] Batch 20 - Loss: 5.313763
[2025-05-10 23:09:14] Batch 25 - Loss: 5.359028
[2025-05-10 23:09:15] Batch 30 - Loss: 5.305219
[2025-05-10 23:09:17] Batch 35 - Loss: 5.230519
[2025-05-10 23:09:23] === Epoch 8/50 Summary ===
Training Loss: 5.250100
Validation Loss: 8.955219
Learning Rate: 0.00003000
[2025-05-10 23:09:24] Batch 0 - Loss: 5.585711
[2025-05-10 23:09:26] Batch 5 - Loss: 5.604477
[2025-05-10 23:09:28] Batch 10 - Loss: 5.435029
[2025-05-10 23:09:29] Batch 15 - Loss: 5.514898
[2025-05-10 23:09:31] Batch 20 - Loss: 5.672601
[2025-05-10 23:09:33] Batch 25 - Loss: 5.774001
[2025-05-10 23:09:35] Batch 30 - Loss: 5.624382
[2025-05-10 23:09:36] Batch 35 - Loss: 5.652514
[2025-05-10 23:09:38] Batch 40 - Loss: 5.582911
[2025-05-10 23:09:40] Batch 45 - Loss: 5.565377
[2025-05-10 23:09:42] Batch 50 - Loss: 5.481013
[2025-05-10 23:09:43] Batch 55 - Loss: 5.489886
[2025-05-10 23:09:45] Batch 60 - Loss: 5.443493
[2025-05-10 23:09:47] Batch 65 - Loss: 5.410460
[2025-05-10 23:09:49] Batch 70 - Loss: 5.381463
[2025-05-10 23:09:50] Batch 75 - Loss: 5.384552
[2025-05-10 23:09:52] Batch 80 - Loss: 5.384814
[2025-05-10 23:09:54] Batch 85 - Loss: 5.331731
[2025-05-10 23:09:56] Batch 90 - Loss: 5.289777
[2025-05-10 23:09:57] Batch 95 - Loss: 5.263508
[2025-05-10 23:10:05] === Epoch 9/50 Summary ===
Training Loss: 5.262100
Validation Loss: 8.532125
Learning Rate: 0.00003000
[2025-05-10 23:10:05] Batch 0 - Loss: 3.978773
[2025-05-10 23:10:07] Batch 5 - Loss: 4.935034
[2025-05-10 23:10:09] Batch 10 - Loss: 4.934185
[2025-05-10 23:10:10] Batch 15 - Loss: 4.940309
[2025-05-10 23:10:12] Batch 20 - Loss: 4.937519
[2025-05-10 23:10:14] Batch 25 - Loss: 5.042307
[2025-05-10 23:10:16] Batch 30 - Loss: 4.951264
[2025-05-10 23:10:17] Batch 35 - Loss: 4.894253
[2025-05-10 23:10:19] Batch 40 - Loss: 4.809835
[2025-05-10 23:10:21] Batch 45 - Loss: 4.814322
[2025-05-10 23:10:23] Batch 50 - Loss: 4.825557
[2025-05-10 23:10:24] Batch 55 - Loss: 4.787498
[2025-05-10 23:10:26] Batch 60 - Loss: 4.815114
[2025-05-10 23:10:28] Batch 65 - Loss: 4.808300
[2025-05-10 23:10:30] Batch 70 - Loss: 4.778165
[2025-05-10 23:10:32] Batch 75 - Loss: 4.773425
[2025-05-10 23:10:33] Batch 80 - Loss: 4.763044
[2025-05-10 23:10:35] Batch 85 - Loss: 4.756599
[2025-05-10 23:10:37] Batch 90 - Loss: 4.718107
[2025-05-10 23:10:39] Batch 95 - Loss: 4.717373
[2025-05-10 23:10:46] === Epoch 10/50 Summary ===
Training Loss: 4.704069
Validation Loss: 6.854133
Learning Rate: 0.00003000
[2025-05-10 23:10:46] Generating detection visualizations for epoch 10...
[2025-05-10 23:10:46] Saved visualization to trained_models/custom_detector\visualizations\epoch_10\sample_1.png
[2025-05-10 23:10:47] Saved visualization to trained_models/custom_detector\visualizations\epoch_10\sample_2.png
[2025-05-10 23:10:47] Saved visualization to trained_models/custom_detector\visualizations\epoch_10\sample_3.png
[2025-05-10 23:10:47] Batch 0 - Loss: 3.523541
[2025-05-10 23:10:49] Batch 5 - Loss: 4.564229
[2025-05-10 23:10:51] Batch 10 - Loss: 4.306266
[2025-05-10 23:10:53] Batch 15 - Loss: 4.778786
[2025-05-10 23:10:55] Batch 20 - Loss: 4.727349
[2025-05-10 23:10:56] Batch 25 - Loss: 4.661338
[2025-05-10 23:10:58] Batch 30 - Loss: 4.605301
[2025-05-10 23:11:00] Batch 35 - Loss: 4.626349
[2025-05-10 23:11:02] Batch 40 - Loss: 4.566100
[2025-05-10 23:11:03] Batch 45 - Loss: 4.475086
[2025-05-10 23:11:05] Batch 50 - Loss: 4.458294
[2025-05-10 23:11:07] Batch 55 - Loss: 4.512075
[2025-05-10 23:11:09] Batch 60 - Loss: 4.548004
[2025-05-10 23:11:11] Batch 65 - Loss: 4.580902
[2025-05-10 23:11:13] Batch 70 - Loss: 4.557557
[2025-05-10 23:11:14] Batch 75 - Loss: 4.528834
[2025-05-10 23:11:16] Batch 80 - Loss: 4.500924
[2025-05-10 23:11:18] Batch 85 - Loss: 4.466914
[2025-05-10 23:11:20] Batch 90 - Loss: 4.440011
[2025-05-10 23:11:21] Batch 95 - Loss: 4.429279
[2025-05-10 23:11:29] === Epoch 11/50 Summary ===
Training Loss: 4.425343
Validation Loss: 6.606254
Learning Rate: 0.00003000
[2025-05-10 23:11:29] Batch 0 - Loss: 3.538514
[2025-05-10 23:11:31] Batch 5 - Loss: 3.817174
[2025-05-10 23:11:33] Batch 10 - Loss: 3.889410
[2025-05-10 23:11:35] Batch 15 - Loss: 4.013523
[2025-05-10 23:11:37] Batch 20 - Loss: 4.021642
[2025-05-10 23:11:38] Batch 25 - Loss: 4.025190
[2025-05-10 23:11:40] Batch 30 - Loss: 3.994736
[2025-05-10 23:11:42] Batch 35 - Loss: 4.000895
[2025-05-10 23:11:48] === Epoch 12/50 Summary ===
Training Loss: 4.012269
Validation Loss: 6.302352
Learning Rate: 0.00003000
[2025-05-10 23:11:49] Batch 0 - Loss: 5.571502
[2025-05-10 23:11:51] Batch 5 - Loss: 5.125697
[2025-05-10 23:11:53] Batch 10 - Loss: 4.697899
[2025-05-10 23:11:54] Batch 15 - Loss: 4.441324
[2025-05-10 23:11:56] Batch 20 - Loss: 4.351110
[2025-05-10 23:11:58] Batch 25 - Loss: 4.475366
[2025-05-10 23:12:00] Batch 30 - Loss: 4.460291
[2025-05-10 23:12:01] Batch 35 - Loss: 4.497796
[2025-05-10 23:12:03] Batch 40 - Loss: 4.522642
[2025-05-10 23:12:05] Batch 45 - Loss: 4.516420
[2025-05-10 23:12:07] Batch 50 - Loss: 4.500522
[2025-05-10 23:12:08] Batch 55 - Loss: 4.463761
[2025-05-10 23:12:10] Batch 60 - Loss: 4.478731
[2025-05-10 23:12:12] Batch 65 - Loss: 4.417004
[2025-05-10 23:12:14] Batch 70 - Loss: 4.434499
[2025-05-10 23:12:15] Batch 75 - Loss: 4.417225
[2025-05-10 23:12:17] Batch 80 - Loss: 4.426220
[2025-05-10 23:12:19] Batch 85 - Loss: 4.395378
[2025-05-10 23:12:21] Batch 90 - Loss: 4.378013
[2025-05-10 23:12:22] Batch 95 - Loss: 4.373987
[2025-05-10 23:12:30] === Epoch 13/50 Summary ===
Training Loss: 4.357601
Validation Loss: 6.224935
Learning Rate: 0.00003000
[2025-05-10 23:12:30] Batch 0 - Loss: 5.375318
[2025-05-10 23:12:32] Batch 5 - Loss: 4.368647
[2025-05-10 23:12:33] Batch 10 - Loss: 4.338757
[2025-05-10 23:12:35] Batch 15 - Loss: 4.407067
[2025-05-10 23:12:37] Batch 20 - Loss: 4.283811
[2025-05-10 23:12:39] Batch 25 - Loss: 4.221501
[2025-05-10 23:12:40] Batch 30 - Loss: 4.206633
[2025-05-10 23:12:42] Batch 35 - Loss: 4.130570
[2025-05-10 23:12:44] Batch 40 - Loss: 4.180172
[2025-05-10 23:12:46] Batch 45 - Loss: 4.192636
[2025-05-10 23:12:47] Batch 50 - Loss: 4.193519
[2025-05-10 23:12:49] Batch 55 - Loss: 4.225352
[2025-05-10 23:12:51] Batch 60 - Loss: 4.188824
[2025-05-10 23:12:53] Batch 65 - Loss: 4.159822
[2025-05-10 23:12:55] Batch 70 - Loss: 4.113766
[2025-05-10 23:12:56] Batch 75 - Loss: 4.092270
[2025-05-10 23:12:58] Batch 80 - Loss: 4.072280
[2025-05-10 23:13:00] Batch 85 - Loss: 4.044975
[2025-05-10 23:13:01] Batch 90 - Loss: 4.052709
[2025-05-10 23:13:03] Batch 95 - Loss: 4.032820
[2025-05-10 23:13:11] === Epoch 14/50 Summary ===
Training Loss: 4.015913
Validation Loss: 5.655243
Learning Rate: 0.00003000
[2025-05-10 23:13:11] Batch 0 - Loss: 4.241427
[2025-05-10 23:13:13] Batch 5 - Loss: 4.222698
[2025-05-10 23:13:14] Batch 10 - Loss: 4.108876
[2025-05-10 23:13:16] Batch 15 - Loss: 4.144065
[2025-05-10 23:13:18] Batch 20 - Loss: 4.180345
[2025-05-10 23:13:20] Batch 25 - Loss: 4.098893
[2025-05-10 23:13:21] Batch 30 - Loss: 4.017051
[2025-05-10 23:13:23] Batch 35 - Loss: 4.012841
[2025-05-10 23:13:25] Batch 40 - Loss: 4.046579
[2025-05-10 23:13:27] Batch 45 - Loss: 4.045448
[2025-05-10 23:13:28] Batch 50 - Loss: 4.017675
[2025-05-10 23:13:30] Batch 55 - Loss: 3.987871
[2025-05-10 23:13:32] Batch 60 - Loss: 3.963886
[2025-05-10 23:13:34] Batch 65 - Loss: 4.018524
[2025-05-10 23:13:35] Batch 70 - Loss: 3.990239
[2025-05-10 23:13:37] Batch 75 - Loss: 3.946358
[2025-05-10 23:13:39] Batch 80 - Loss: 3.917544
[2025-05-10 23:13:41] Batch 85 - Loss: 3.896236
[2025-05-10 23:13:42] Batch 90 - Loss: 3.887862
[2025-05-10 23:13:44] Batch 95 - Loss: 3.859214
[2025-05-10 23:13:51] === Epoch 15/50 Summary ===
Training Loss: 3.859670
Validation Loss: 5.493212
Learning Rate: 0.00003000
[2025-05-10 23:13:51] Generating detection visualizations for epoch 15...
[2025-05-10 23:13:52] Saved visualization to trained_models/custom_detector\visualizations\epoch_15\sample_1.png
[2025-05-10 23:13:52] Saved visualization to trained_models/custom_detector\visualizations\epoch_15\sample_2.png
[2025-05-10 23:13:52] Saved visualization to trained_models/custom_detector\visualizations\epoch_15\sample_3.png
[2025-05-10 23:13:53] Batch 0 - Loss: 3.394492
[2025-05-10 23:13:54] Batch 5 - Loss: 3.208871
[2025-05-10 23:13:56] Batch 10 - Loss: 3.518017
[2025-05-10 23:13:58] Batch 15 - Loss: 3.652906
[2025-05-10 23:14:00] Batch 20 - Loss: 3.628231
[2025-05-10 23:14:01] Batch 25 - Loss: 3.655846
[2025-05-10 23:14:03] Batch 30 - Loss: 3.591408
[2025-05-10 23:14:05] Batch 35 - Loss: 3.573487
[2025-05-10 23:14:11] === Epoch 16/50 Summary ===
Training Loss: 3.565977
Validation Loss: 5.520217
Learning Rate: 0.00003000
[2025-05-10 23:14:11] Batch 0 - Loss: 4.101627
[2025-05-10 23:14:13] Batch 5 - Loss: 4.381246
[2025-05-10 23:14:15] Batch 10 - Loss: 4.330860
[2025-05-10 23:14:17] Batch 15 - Loss: 4.196235
[2025-05-10 23:14:18] Batch 20 - Loss: 4.149146
[2025-05-10 23:14:20] Batch 25 - Loss: 4.220869
[2025-05-10 23:14:22] Batch 30 - Loss: 4.208470
[2025-05-10 23:14:24] Batch 35 - Loss: 4.193297
[2025-05-10 23:14:25] Batch 40 - Loss: 4.160520
[2025-05-10 23:14:27] Batch 45 - Loss: 4.158790
[2025-05-10 23:14:29] Batch 50 - Loss: 4.136137
[2025-05-10 23:14:31] Batch 55 - Loss: 4.174591
[2025-05-10 23:14:32] Batch 60 - Loss: 4.123269
[2025-05-10 23:14:34] Batch 65 - Loss: 4.122688
[2025-05-10 23:14:36] Batch 70 - Loss: 4.064065
[2025-05-10 23:14:38] Batch 75 - Loss: 4.052322
[2025-05-10 23:14:39] Batch 80 - Loss: 4.039959
[2025-05-10 23:14:41] Batch 85 - Loss: 4.031579
[2025-05-10 23:14:43] Batch 90 - Loss: 4.033390
[2025-05-10 23:14:45] Batch 95 - Loss: 4.009820
[2025-05-10 23:14:52] === Epoch 17/50 Summary ===
Training Loss: 3.985862
Validation Loss: 5.807902
Learning Rate: 0.00003000
[2025-05-10 23:14:52] Batch 0 - Loss: 3.321489
[2025-05-10 23:14:54] Batch 5 - Loss: 3.991800
[2025-05-10 23:14:56] Batch 10 - Loss: 3.975190
[2025-05-10 23:14:57] Batch 15 - Loss: 3.899348
[2025-05-10 23:14:59] Batch 20 - Loss: 3.833905
[2025-05-10 23:15:01] Batch 25 - Loss: 3.843552
[2025-05-10 23:15:03] Batch 30 - Loss: 3.796257
[2025-05-10 23:15:04] Batch 35 - Loss: 3.731385
[2025-05-10 23:15:06] Batch 40 - Loss: 3.759500
[2025-05-10 23:15:08] Batch 45 - Loss: 3.780524
[2025-05-10 23:15:10] Batch 50 - Loss: 3.746126
[2025-05-10 23:15:11] Batch 55 - Loss: 3.735790
[2025-05-10 23:15:13] Batch 60 - Loss: 3.724613
[2025-05-10 23:15:15] Batch 65 - Loss: 3.750851
[2025-05-10 23:15:17] Batch 70 - Loss: 3.758981
[2025-05-10 23:15:18] Batch 75 - Loss: 3.757497
[2025-05-10 23:15:20] Batch 80 - Loss: 3.755476
[2025-05-10 23:15:22] Batch 85 - Loss: 3.734909
[2025-05-10 23:15:24] Batch 90 - Loss: 3.706499
[2025-05-10 23:15:25] Batch 95 - Loss: 3.682686
[2025-05-10 23:15:33] === Epoch 18/50 Summary ===
Training Loss: 3.688509
Validation Loss: 5.308036
Learning Rate: 0.00003000
[2025-05-10 23:15:33] Batch 0 - Loss: 4.021354
[2025-05-10 23:15:35] Batch 5 - Loss: 4.170932
[2025-05-10 23:15:37] Batch 10 - Loss: 3.933645
[2025-05-10 23:15:38] Batch 15 - Loss: 3.829756
[2025-05-10 23:15:40] Batch 20 - Loss: 3.830139
[2025-05-10 23:15:42] Batch 25 - Loss: 3.854297
[2025-05-10 23:15:44] Batch 30 - Loss: 3.809500
[2025-05-10 23:15:45] Batch 35 - Loss: 3.761542
[2025-05-10 23:15:47] Batch 40 - Loss: 3.770591
[2025-05-10 23:15:49] Batch 45 - Loss: 3.717940
[2025-05-10 23:15:51] Batch 50 - Loss: 3.672468
[2025-05-10 23:15:52] Batch 55 - Loss: 3.620651
[2025-05-10 23:15:54] Batch 60 - Loss: 3.623487
[2025-05-10 23:15:56] Batch 65 - Loss: 3.603695
[2025-05-10 23:15:58] Batch 70 - Loss: 3.598909
[2025-05-10 23:15:59] Batch 75 - Loss: 3.582787
[2025-05-10 23:16:01] Batch 80 - Loss: 3.566597
[2025-05-10 23:16:03] Batch 85 - Loss: 3.562672
[2025-05-10 23:16:04] Batch 90 - Loss: 3.522085
[2025-05-10 23:16:06] Batch 95 - Loss: 3.507441
[2025-05-10 23:16:13] === Epoch 19/50 Summary ===
Training Loss: 3.487375
Validation Loss: 5.413713
Learning Rate: 0.00003000
[2025-05-10 23:16:14] Batch 0 - Loss: 2.769253
[2025-05-10 23:16:15] Batch 5 - Loss: 3.290736
[2025-05-10 23:16:17] Batch 10 - Loss: 3.226801
[2025-05-10 23:16:19] Batch 15 - Loss: 3.307871
[2025-05-10 23:16:21] Batch 20 - Loss: 3.187415
[2025-05-10 23:16:22] Batch 25 - Loss: 3.226522
[2025-05-10 23:16:24] Batch 30 - Loss: 3.257270
[2025-05-10 23:16:26] Batch 35 - Loss: 3.235107
[2025-05-10 23:16:32] === Epoch 20/50 Summary ===
Training Loss: 3.251981
Validation Loss: 5.271969
Learning Rate: 0.00003000
[2025-05-10 23:16:32] Generating detection visualizations for epoch 20...
[2025-05-10 23:16:32] Saved visualization to trained_models/custom_detector\visualizations\epoch_20\sample_1.png
[2025-05-10 23:16:33] Saved visualization to trained_models/custom_detector\visualizations\epoch_20\sample_2.png
[2025-05-10 23:16:33] Saved visualization to trained_models/custom_detector\visualizations\epoch_20\sample_3.png
[2025-05-10 23:16:34] Batch 0 - Loss: 4.930338
[2025-05-10 23:16:36] Batch 5 - Loss: 3.951325
[2025-05-10 23:16:37] Batch 10 - Loss: 4.028721
[2025-05-10 23:16:39] Batch 15 - Loss: 3.873553
[2025-05-10 23:16:41] Batch 20 - Loss: 3.878796
[2025-05-10 23:16:42] Batch 25 - Loss: 3.809687
[2025-05-10 23:16:44] Batch 30 - Loss: 3.830068
[2025-05-10 23:16:46] Batch 35 - Loss: 3.835825
[2025-05-10 23:16:48] Batch 40 - Loss: 3.813609
[2025-05-10 23:16:50] Batch 45 - Loss: 3.792426
[2025-05-10 23:16:51] Batch 50 - Loss: 3.808465
[2025-05-10 23:16:53] Batch 55 - Loss: 3.820043
[2025-05-10 23:16:55] Batch 60 - Loss: 3.808508
[2025-05-10 23:16:57] Batch 65 - Loss: 3.791843
[2025-05-10 23:16:58] Batch 70 - Loss: 3.761675
[2025-05-10 23:17:00] Batch 75 - Loss: 3.717532
[2025-05-10 23:17:02] Batch 80 - Loss: 3.685807
[2025-05-10 23:17:04] Batch 85 - Loss: 3.664581
[2025-05-10 23:17:05] Batch 90 - Loss: 3.659076
[2025-05-10 23:17:07] Batch 95 - Loss: 3.637588
[2025-05-10 23:17:14] === Epoch 21/50 Summary ===
Training Loss: 3.643085
Validation Loss: 5.397355
Learning Rate: 0.00003000
[2025-05-10 23:17:15] Batch 0 - Loss: 3.629266
[2025-05-10 23:17:16] Batch 5 - Loss: 3.776251
[2025-05-10 23:17:18] Batch 10 - Loss: 3.651500
[2025-05-10 23:17:20] Batch 15 - Loss: 3.535183
[2025-05-10 23:17:22] Batch 20 - Loss: 3.567039
[2025-05-10 23:17:23] Batch 25 - Loss: 3.583655
[2025-05-10 23:17:25] Batch 30 - Loss: 3.627712
[2025-05-10 23:17:27] Batch 35 - Loss: 3.550294
[2025-05-10 23:17:29] Batch 40 - Loss: 3.498266
[2025-05-10 23:17:30] Batch 45 - Loss: 3.489318
[2025-05-10 23:17:32] Batch 50 - Loss: 3.498196
[2025-05-10 23:17:34] Batch 55 - Loss: 3.477984
[2025-05-10 23:17:36] Batch 60 - Loss: 3.463424
[2025-05-10 23:17:37] Batch 65 - Loss: 3.468250
[2025-05-10 23:17:39] Batch 70 - Loss: 3.489540
[2025-05-10 23:17:41] Batch 75 - Loss: 3.464577
[2025-05-10 23:17:43] Batch 80 - Loss: 3.450585
[2025-05-10 23:17:44] Batch 85 - Loss: 3.438292
[2025-05-10 23:17:46] Batch 90 - Loss: 3.444170
[2025-05-10 23:17:48] Batch 95 - Loss: 3.439447
[2025-05-10 23:17:56] === Epoch 22/50 Summary ===
Training Loss: 3.439499
Validation Loss: 5.072526
Learning Rate: 0.00003000
[2025-05-10 23:17:56] Batch 0 - Loss: 2.752139
[2025-05-10 23:17:58] Batch 5 - Loss: 3.254702
[2025-05-10 23:17:59] Batch 10 - Loss: 3.420075
[2025-05-10 23:18:01] Batch 15 - Loss: 3.412065
[2025-05-10 23:18:03] Batch 20 - Loss: 3.322339
[2025-05-10 23:18:05] Batch 25 - Loss: 3.382015
[2025-05-10 23:18:06] Batch 30 - Loss: 3.337370
[2025-05-10 23:18:08] Batch 35 - Loss: 3.311696
[2025-05-10 23:18:10] Batch 40 - Loss: 3.310763
[2025-05-10 23:18:12] Batch 45 - Loss: 3.289737
[2025-05-10 23:18:13] Batch 50 - Loss: 3.274081
[2025-05-10 23:18:15] Batch 55 - Loss: 3.254026
[2025-05-10 23:18:17] Batch 60 - Loss: 3.250360
[2025-05-10 23:18:19] Batch 65 - Loss: 3.270557
[2025-05-10 23:18:20] Batch 70 - Loss: 3.255780
[2025-05-10 23:18:22] Batch 75 - Loss: 3.266649
[2025-05-10 23:18:24] Batch 80 - Loss: 3.266888
[2025-05-10 23:18:26] Batch 85 - Loss: 3.246395
[2025-05-10 23:18:28] Batch 90 - Loss: 3.234053
[2025-05-10 23:18:29] Batch 95 - Loss: 3.226255
[2025-05-10 23:18:37] === Epoch 23/50 Summary ===
Training Loss: 3.222374
Validation Loss: 5.323166
Learning Rate: 0.00003000
[2025-05-10 23:18:37] Batch 0 - Loss: 2.683641
[2025-05-10 23:18:39] Batch 5 - Loss: 3.050598
[2025-05-10 23:18:40] Batch 10 - Loss: 2.849667
[2025-05-10 23:18:42] Batch 15 - Loss: 2.979417
[2025-05-10 23:18:44] Batch 20 - Loss: 3.047187
[2025-05-10 23:18:46] Batch 25 - Loss: 3.069994
[2025-05-10 23:18:47] Batch 30 - Loss: 3.048665
[2025-05-10 23:18:49] Batch 35 - Loss: 3.040323
[2025-05-10 23:18:55] === Epoch 24/50 Summary ===
Training Loss: 3.039576
Validation Loss: 5.111930
Learning Rate: 0.00003000
[2025-05-10 23:18:56] Batch 0 - Loss: 2.839150
[2025-05-10 23:18:58] Batch 5 - Loss: 3.381850
[2025-05-10 23:19:00] Batch 10 - Loss: 3.606776
[2025-05-10 23:19:01] Batch 15 - Loss: 3.551944
[2025-05-10 23:19:03] Batch 20 - Loss: 3.504087
[2025-05-10 23:19:05] Batch 25 - Loss: 3.534309
[2025-05-10 23:19:07] Batch 30 - Loss: 3.626423
[2025-05-10 23:19:09] Batch 35 - Loss: 3.587312
[2025-05-10 23:19:10] Batch 40 - Loss: 3.554306
[2025-05-10 23:19:12] Batch 45 - Loss: 3.588972
[2025-05-10 23:19:14] Batch 50 - Loss: 3.573760
[2025-05-10 23:19:16] Batch 55 - Loss: 3.561958
[2025-05-10 23:19:18] Batch 60 - Loss: 3.578679
[2025-05-10 23:19:19] Batch 65 - Loss: 3.553693
[2025-05-10 23:19:21] Batch 70 - Loss: 3.548235
[2025-05-10 23:19:23] Batch 75 - Loss: 3.514055
[2025-05-10 23:19:25] Batch 80 - Loss: 3.513798
[2025-05-10 23:19:27] Batch 85 - Loss: 3.476989
[2025-05-10 23:19:28] Batch 90 - Loss: 3.474721
[2025-05-10 23:19:30] Batch 95 - Loss: 3.450852
[2025-05-10 23:19:38] === Epoch 25/50 Summary ===
Training Loss: 3.426349
Validation Loss: 5.130704
Learning Rate: 0.00003000
[2025-05-10 23:19:38] Generating detection visualizations for epoch 25...
[2025-05-10 23:19:38] Saved visualization to trained_models/custom_detector\visualizations\epoch_25\sample_1.png
[2025-05-10 23:19:38] Saved visualization to trained_models/custom_detector\visualizations\epoch_25\sample_2.png
[2025-05-10 23:19:39] Saved visualization to trained_models/custom_detector\visualizations\epoch_25\sample_3.png
[2025-05-10 23:19:39] Batch 0 - Loss: 3.316372
[2025-05-10 23:19:41] Batch 5 - Loss: 3.212003
[2025-05-10 23:19:43] Batch 10 - Loss: 3.135998
[2025-05-10 23:19:44] Batch 15 - Loss: 3.100107
[2025-05-10 23:19:46] Batch 20 - Loss: 3.148802
[2025-05-10 23:19:48] Batch 25 - Loss: 3.081655
[2025-05-10 23:19:50] Batch 30 - Loss: 3.062966
[2025-05-10 23:19:52] Batch 35 - Loss: 3.047889
[2025-05-10 23:19:54] Batch 40 - Loss: 3.075904
[2025-05-10 23:19:56] Batch 45 - Loss: 3.090408
[2025-05-10 23:19:57] Batch 50 - Loss: 3.083492
[2025-05-10 23:19:59] Batch 55 - Loss: 3.101281
[2025-05-10 23:20:01] Batch 60 - Loss: 3.082361
[2025-05-10 23:20:03] Batch 65 - Loss: 3.056075
[2025-05-10 23:20:05] Batch 70 - Loss: 3.086050
[2025-05-10 23:20:07] Batch 75 - Loss: 3.118400
[2025-05-10 23:20:08] Batch 80 - Loss: 3.130120
[2025-05-10 23:20:10] Batch 85 - Loss: 3.164765
[2025-05-10 23:20:12] Batch 90 - Loss: 3.166341
[2025-05-10 23:20:14] Batch 95 - Loss: 3.149140
[2025-05-10 23:20:21] === Epoch 26/50 Summary ===
Training Loss: 3.137625
Validation Loss: 5.003412
Learning Rate: 0.00003000
[2025-05-10 23:20:22] Batch 0 - Loss: 2.807272
[2025-05-10 23:20:24] Batch 5 - Loss: 3.185852
[2025-05-10 23:20:25] Batch 10 - Loss: 3.196677
[2025-05-10 23:20:27] Batch 15 - Loss: 3.176331
[2025-05-10 23:20:29] Batch 20 - Loss: 3.218347
[2025-05-10 23:20:31] Batch 25 - Loss: 3.178919
[2025-05-10 23:20:33] Batch 30 - Loss: 3.131742
[2025-05-10 23:20:34] Batch 35 - Loss: 3.165417
[2025-05-10 23:20:36] Batch 40 - Loss: 3.133605
[2025-05-10 23:20:38] Batch 45 - Loss: 3.164305
[2025-05-10 23:20:40] Batch 50 - Loss: 3.167226
[2025-05-10 23:20:42] Batch 55 - Loss: 3.145429
[2025-05-10 23:20:44] Batch 60 - Loss: 3.105746
[2025-05-10 23:20:46] Batch 65 - Loss: 3.088445
[2025-05-10 23:20:47] Batch 70 - Loss: 3.069233
[2025-05-10 23:20:49] Batch 75 - Loss: 3.076357
[2025-05-10 23:20:51] Batch 80 - Loss: 3.066309
[2025-05-10 23:20:53] Batch 85 - Loss: 3.068869
[2025-05-10 23:20:54] Batch 90 - Loss: 3.068057
[2025-05-10 23:20:56] Batch 95 - Loss: 3.078111
[2025-05-10 23:21:04] === Epoch 27/50 Summary ===
Training Loss: 3.063982
Validation Loss: 5.035608
Learning Rate: 0.00003000
[2025-05-10 23:21:04] Batch 0 - Loss: 2.246058
[2025-05-10 23:21:06] Batch 5 - Loss: 2.802413
[2025-05-10 23:21:08] Batch 10 - Loss: 2.805357
[2025-05-10 23:21:10] Batch 15 - Loss: 2.808794
[2025-05-10 23:21:12] Batch 20 - Loss: 2.907110
[2025-05-10 23:21:13] Batch 25 - Loss: 2.857480
[2025-05-10 23:21:15] Batch 30 - Loss: 2.862885
[2025-05-10 23:21:17] Batch 35 - Loss: 2.848462
[2025-05-10 23:21:23] === Epoch 28/50 Summary ===
Training Loss: 2.869045
Validation Loss: 5.012718
Learning Rate: 0.00003000
[2025-05-10 23:21:24] Batch 0 - Loss: 3.100622
[2025-05-10 23:21:25] Batch 5 - Loss: 3.182762
[2025-05-10 23:21:27] Batch 10 - Loss: 3.269692
[2025-05-10 23:21:29] Batch 15 - Loss: 3.365656
[2025-05-10 23:21:31] Batch 20 - Loss: 3.432748
[2025-05-10 23:21:32] Batch 25 - Loss: 3.446321
[2025-05-10 23:21:34] Batch 30 - Loss: 3.448650
[2025-05-10 23:21:36] Batch 35 - Loss: 3.440579
[2025-05-10 23:21:37] Batch 40 - Loss: 3.464476
[2025-05-10 23:21:39] Batch 45 - Loss: 3.443281
[2025-05-10 23:21:41] Batch 50 - Loss: 3.377072
[2025-05-10 23:21:43] Batch 55 - Loss: 3.385220
[2025-05-10 23:21:44] Batch 60 - Loss: 3.392103
[2025-05-10 23:21:46] Batch 65 - Loss: 3.375796
[2025-05-10 23:21:48] Batch 70 - Loss: 3.335613
[2025-05-10 23:21:50] Batch 75 - Loss: 3.301636
[2025-05-10 23:21:51] Batch 80 - Loss: 3.299116
[2025-05-10 23:21:53] Batch 85 - Loss: 3.263866
[2025-05-10 23:21:55] Batch 90 - Loss: 3.239626
[2025-05-10 23:21:57] Batch 95 - Loss: 3.224193
[2025-05-10 23:22:04] === Epoch 29/50 Summary ===
Training Loss: 3.199195
Validation Loss: 5.097660
Learning Rate: 0.00003000
[2025-05-10 23:22:04] Batch 0 - Loss: 2.630422
[2025-05-10 23:22:06] Batch 5 - Loss: 2.955261
[2025-05-10 23:22:08] Batch 10 - Loss: 3.083802
[2025-05-10 23:22:09] Batch 15 - Loss: 3.100558
[2025-05-10 23:22:11] Batch 20 - Loss: 3.155768
[2025-05-10 23:22:13] Batch 25 - Loss: 3.167274
[2025-05-10 23:22:15] Batch 30 - Loss: 3.135775
[2025-05-10 23:22:16] Batch 35 - Loss: 3.100689
[2025-05-10 23:22:18] Batch 40 - Loss: 3.099342
[2025-05-10 23:22:20] Batch 45 - Loss: 3.088131
[2025-05-10 23:22:21] Batch 50 - Loss: 3.097529
[2025-05-10 23:22:23] Batch 55 - Loss: 3.100955
[2025-05-10 23:22:25] Batch 60 - Loss: 3.091441
[2025-05-10 23:22:27] Batch 65 - Loss: 3.091968
[2025-05-10 23:22:28] Batch 70 - Loss: 3.090964
[2025-05-10 23:22:30] Batch 75 - Loss: 3.098731
[2025-05-10 23:22:32] Batch 80 - Loss: 3.092507
[2025-05-10 23:22:34] Batch 85 - Loss: 3.087885
[2025-05-10 23:22:35] Batch 90 - Loss: 3.080107
[2025-05-10 23:22:37] Batch 95 - Loss: 3.060976
[2025-05-10 23:22:44] === Epoch 30/50 Summary ===
Training Loss: 3.061172
Validation Loss: 5.057445
Learning Rate: 0.00003000
[2025-05-10 23:22:44] Generating detection visualizations for epoch 30...
[2025-05-10 23:22:45] Saved visualization to trained_models/custom_detector\visualizations\epoch_30\sample_1.png
[2025-05-10 23:22:45] Saved visualization to trained_models/custom_detector\visualizations\epoch_30\sample_2.png
[2025-05-10 23:22:45] Saved visualization to trained_models/custom_detector\visualizations\epoch_30\sample_3.png
[2025-05-10 23:22:46] Batch 0 - Loss: 3.190088
[2025-05-10 23:22:48] Batch 5 - Loss: 2.964962
[2025-05-10 23:22:49] Batch 10 - Loss: 2.883250
[2025-05-10 23:22:51] Batch 15 - Loss: 2.950686
[2025-05-10 23:22:53] Batch 20 - Loss: 2.918986
[2025-05-10 23:22:55] Batch 25 - Loss: 2.942304
[2025-05-10 23:22:56] Batch 30 - Loss: 2.892292
[2025-05-10 23:22:58] Batch 35 - Loss: 2.952270
[2025-05-10 23:23:00] Batch 40 - Loss: 2.968382
[2025-05-10 23:23:02] Batch 45 - Loss: 2.946598
[2025-05-10 23:23:04] Batch 50 - Loss: 2.932656
[2025-05-10 23:23:06] Batch 55 - Loss: 2.941962
[2025-05-10 23:23:08] Batch 60 - Loss: 2.959831
[2025-05-10 23:23:09] Batch 65 - Loss: 2.953584
[2025-05-10 23:23:11] Batch 70 - Loss: 2.970914
[2025-05-10 23:23:13] Batch 75 - Loss: 2.952240
[2025-05-10 23:23:15] Batch 80 - Loss: 2.949778
[2025-05-10 23:23:17] Batch 85 - Loss: 2.927638
[2025-05-10 23:23:18] Batch 90 - Loss: 2.927151
[2025-05-10 23:23:20] Batch 95 - Loss: 2.904533
[2025-05-10 23:23:28] === Epoch 31/50 Summary ===
Training Loss: 2.891611
Validation Loss: 5.001688
Learning Rate: 0.00003000
[2025-05-10 23:23:28] Batch 0 - Loss: 3.062567
[2025-05-10 23:23:30] Batch 5 - Loss: 2.639171
[2025-05-10 23:23:31] Batch 10 - Loss: 2.700474
[2025-05-10 23:23:33] Batch 15 - Loss: 2.666211
[2025-05-10 23:23:35] Batch 20 - Loss: 2.579304
[2025-05-10 23:23:37] Batch 25 - Loss: 2.592822
[2025-05-10 23:23:38] Batch 30 - Loss: 2.576522
[2025-05-10 23:23:40] Batch 35 - Loss: 2.584389
[2025-05-10 23:23:46] === Epoch 32/50 Summary ===
Training Loss: 2.582380
Validation Loss: 5.008040
Learning Rate: 0.00003000
[2025-05-10 23:23:47] Batch 0 - Loss: 3.564313
[2025-05-10 23:23:49] Batch 5 - Loss: 3.266536
[2025-05-10 23:23:50] Batch 10 - Loss: 3.359699
[2025-05-10 23:23:52] Batch 15 - Loss: 3.252964
[2025-05-10 23:23:54] Batch 20 - Loss: 3.189062
[2025-05-10 23:23:56] Batch 25 - Loss: 3.168777
[2025-05-10 23:23:57] Batch 30 - Loss: 3.138522
[2025-05-10 23:23:59] Batch 35 - Loss: 3.148520
[2025-05-10 23:24:01] Batch 40 - Loss: 3.158488
[2025-05-10 23:24:03] Batch 45 - Loss: 3.103963
[2025-05-10 23:24:04] Batch 50 - Loss: 3.061740
[2025-05-10 23:24:06] Batch 55 - Loss: 3.091064
[2025-05-10 23:24:08] Batch 60 - Loss: 3.110982
[2025-05-10 23:24:10] Batch 65 - Loss: 3.100261
[2025-05-10 23:24:11] Batch 70 - Loss: 3.080366
[2025-05-10 23:24:13] Batch 75 - Loss: 3.056882
[2025-05-10 23:24:15] Batch 80 - Loss: 3.041228
[2025-05-10 23:24:17] Batch 85 - Loss: 3.030502
[2025-05-10 23:24:18] Batch 90 - Loss: 3.038174
[2025-05-10 23:24:20] Batch 95 - Loss: 3.035689
[2025-05-10 23:24:27] === Epoch 33/50 Summary ===
Training Loss: 3.016421
Validation Loss: 5.055242
Learning Rate: 0.00003000
[2025-05-10 23:24:28] Batch 0 - Loss: 3.450840
[2025-05-10 23:24:29] Batch 5 - Loss: 2.810982
[2025-05-10 23:24:31] Batch 10 - Loss: 2.767099
[2025-05-10 23:24:33] Batch 15 - Loss: 2.807160
[2025-05-10 23:24:35] Batch 20 - Loss: 2.734684
[2025-05-10 23:24:36] Batch 25 - Loss: 2.718864
[2025-05-10 23:24:38] Batch 30 - Loss: 2.743569
[2025-05-10 23:24:40] Batch 35 - Loss: 2.731582
[2025-05-10 23:24:42] Batch 40 - Loss: 2.696461
[2025-05-10 23:24:44] Batch 45 - Loss: 2.731839
[2025-05-10 23:24:45] Batch 50 - Loss: 2.717300
[2025-05-10 23:24:47] Batch 55 - Loss: 2.691428
[2025-05-10 23:24:49] Batch 60 - Loss: 2.747468
[2025-05-10 23:24:51] Batch 65 - Loss: 2.753185
[2025-05-10 23:24:52] Batch 70 - Loss: 2.763699
[2025-05-10 23:24:54] Batch 75 - Loss: 2.760909
[2025-05-10 23:24:56] Batch 80 - Loss: 2.750205
[2025-05-10 23:24:58] Batch 85 - Loss: 2.766214
[2025-05-10 23:24:59] Batch 90 - Loss: 2.769884
[2025-05-10 23:25:01] Batch 95 - Loss: 2.768630
[2025-05-10 23:25:09] === Epoch 34/50 Summary ===
Training Loss: 2.762345
Validation Loss: 4.942025
Learning Rate: 0.00003000
[2025-05-10 23:25:09] Batch 0 - Loss: 2.462506
[2025-05-10 23:25:11] Batch 5 - Loss: 2.543573
[2025-05-10 23:25:12] Batch 10 - Loss: 2.566515
[2025-05-10 23:25:14] Batch 15 - Loss: 2.620777
[2025-05-10 23:25:16] Batch 20 - Loss: 2.676862
[2025-05-10 23:25:18] Batch 25 - Loss: 2.766116
[2025-05-10 23:25:19] Batch 30 - Loss: 2.776286
[2025-05-10 23:25:21] Batch 35 - Loss: 2.802224
[2025-05-10 23:25:23] Batch 40 - Loss: 2.791305
[2025-05-10 23:25:25] Batch 45 - Loss: 2.776851
[2025-05-10 23:25:26] Batch 50 - Loss: 2.757125
[2025-05-10 23:25:28] Batch 55 - Loss: 2.739068
[2025-05-10 23:25:30] Batch 60 - Loss: 2.743366
[2025-05-10 23:25:32] Batch 65 - Loss: 2.738901
[2025-05-10 23:25:33] Batch 70 - Loss: 2.703326
[2025-05-10 23:25:35] Batch 75 - Loss: 2.688975
[2025-05-10 23:25:37] Batch 80 - Loss: 2.682548
[2025-05-10 23:25:39] Batch 85 - Loss: 2.676821
[2025-05-10 23:25:40] Batch 90 - Loss: 2.674891
[2025-05-10 23:25:42] Batch 95 - Loss: 2.651005
[2025-05-10 23:25:50] === Epoch 35/50 Summary ===
Training Loss: 2.646672
Validation Loss: 4.824316
Learning Rate: 0.00003000
[2025-05-10 23:25:50] Generating detection visualizations for epoch 35...
[2025-05-10 23:25:50] Saved visualization to trained_models/custom_detector\visualizations\epoch_35\sample_1.png
[2025-05-10 23:25:50] Saved visualization to trained_models/custom_detector\visualizations\epoch_35\sample_2.png
[2025-05-10 23:25:51] Saved visualization to trained_models/custom_detector\visualizations\epoch_35\sample_3.png
[2025-05-10 23:25:51] Batch 0 - Loss: 2.965373
[2025-05-10 23:25:53] Batch 5 - Loss: 2.535780
[2025-05-10 23:25:54] Batch 10 - Loss: 2.514059
[2025-05-10 23:25:56] Batch 15 - Loss: 2.473869
[2025-05-10 23:25:58] Batch 20 - Loss: 2.486849
[2025-05-10 23:26:00] Batch 25 - Loss: 2.469468
[2025-05-10 23:26:01] Batch 30 - Loss: 2.496130
[2025-05-10 23:26:03] Batch 35 - Loss: 2.476756
[2025-05-10 23:26:09] === Epoch 36/50 Summary ===
Training Loss: 2.469810
Validation Loss: 5.015906
Learning Rate: 0.00003000
[2025-05-10 23:26:10] Batch 0 - Loss: 2.907457
[2025-05-10 23:26:12] Batch 5 - Loss: 2.848953
[2025-05-10 23:26:13] Batch 10 - Loss: 3.055635
[2025-05-10 23:26:15] Batch 15 - Loss: 3.104934
[2025-05-10 23:26:17] Batch 20 - Loss: 3.054532
[2025-05-10 23:26:19] Batch 25 - Loss: 3.138052
[2025-05-10 23:26:20] Batch 30 - Loss: 3.097772
[2025-05-10 23:26:22] Batch 35 - Loss: 3.073950
[2025-05-10 23:26:24] Batch 40 - Loss: 3.046158
[2025-05-10 23:26:26] Batch 45 - Loss: 3.055761
[2025-05-10 23:26:28] Batch 50 - Loss: 3.042023
[2025-05-10 23:26:29] Batch 55 - Loss: 3.014532
[2025-05-10 23:26:31] Batch 60 - Loss: 2.986181
[2025-05-10 23:26:33] Batch 65 - Loss: 2.953928
[2025-05-10 23:26:35] Batch 70 - Loss: 2.931972
[2025-05-10 23:26:36] Batch 75 - Loss: 2.912708
[2025-05-10 23:26:38] Batch 80 - Loss: 2.894794
[2025-05-10 23:26:40] Batch 85 - Loss: 2.864264
[2025-05-10 23:26:42] Batch 90 - Loss: 2.857012
[2025-05-10 23:26:43] Batch 95 - Loss: 2.837965
[2025-05-10 23:26:51] === Epoch 37/50 Summary ===
Training Loss: 2.817867
Validation Loss: 4.916607
Learning Rate: 0.00003000
[2025-05-10 23:26:51] Batch 0 - Loss: 2.292124
[2025-05-10 23:26:53] Batch 5 - Loss: 2.596476
[2025-05-10 23:26:54] Batch 10 - Loss: 2.606561
[2025-05-10 23:26:56] Batch 15 - Loss: 2.584709
[2025-05-10 23:26:58] Batch 20 - Loss: 2.659550
[2025-05-10 23:27:00] Batch 25 - Loss: 2.710707
[2025-05-10 23:27:01] Batch 30 - Loss: 2.674554
[2025-05-10 23:27:03] Batch 35 - Loss: 2.666866
[2025-05-10 23:27:05] Batch 40 - Loss: 2.683928
[2025-05-10 23:27:07] Batch 45 - Loss: 2.690404
[2025-05-10 23:27:09] Batch 50 - Loss: 2.703040
[2025-05-10 23:27:10] Batch 55 - Loss: 2.692370
[2025-05-10 23:27:12] Batch 60 - Loss: 2.665832
[2025-05-10 23:27:14] Batch 65 - Loss: 2.638170
[2025-05-10 23:27:16] Batch 70 - Loss: 2.636606
[2025-05-10 23:27:17] Batch 75 - Loss: 2.621943
[2025-05-10 23:27:19] Batch 80 - Loss: 2.626029
[2025-05-10 23:27:21] Batch 85 - Loss: 2.637998
[2025-05-10 23:27:23] Batch 90 - Loss: 2.628843
[2025-05-10 23:27:24] Batch 95 - Loss: 2.639741
[2025-05-10 23:27:32] === Epoch 38/50 Summary ===
Training Loss: 2.641341
Validation Loss: 4.741395
Learning Rate: 0.00003000
[2025-05-10 23:27:32] Batch 0 - Loss: 2.202990
[2025-05-10 23:27:34] Batch 5 - Loss: 2.536538
[2025-05-10 23:27:35] Batch 10 - Loss: 2.621950
[2025-05-10 23:27:37] Batch 15 - Loss: 2.621358
[2025-05-10 23:27:39] Batch 20 - Loss: 2.716525
[2025-05-10 23:27:41] Batch 25 - Loss: 2.713591
[2025-05-10 23:27:43] Batch 30 - Loss: 2.693254
[2025-05-10 23:27:44] Batch 35 - Loss: 2.651427
[2025-05-10 23:27:46] Batch 40 - Loss: 2.628687
[2025-05-10 23:27:48] Batch 45 - Loss: 2.594038
[2025-05-10 23:27:50] Batch 50 - Loss: 2.584310
[2025-05-10 23:27:51] Batch 55 - Loss: 2.580950
[2025-05-10 23:27:53] Batch 60 - Loss: 2.586617
[2025-05-10 23:27:55] Batch 65 - Loss: 2.573193
[2025-05-10 23:27:57] Batch 70 - Loss: 2.564076
[2025-05-10 23:27:59] Batch 75 - Loss: 2.568575
[2025-05-10 23:28:00] Batch 80 - Loss: 2.560272
[2025-05-10 23:28:02] Batch 85 - Loss: 2.552221
[2025-05-10 23:28:04] Batch 90 - Loss: 2.539481
[2025-05-10 23:28:05] Batch 95 - Loss: 2.519646
[2025-05-10 23:28:13] === Epoch 39/50 Summary ===
Training Loss: 2.517633
Validation Loss: 4.785569
Learning Rate: 0.00003000
[2025-05-10 23:28:13] Batch 0 - Loss: 1.721793
[2025-05-10 23:28:15] Batch 5 - Loss: 2.184014
[2025-05-10 23:28:16] Batch 10 - Loss: 2.287237
[2025-05-10 23:28:18] Batch 15 - Loss: 2.300997
[2025-05-10 23:28:20] Batch 20 - Loss: 2.378650
[2025-05-10 23:28:22] Batch 25 - Loss: 2.384887
[2025-05-10 23:28:23] Batch 30 - Loss: 2.362451
[2025-05-10 23:28:25] Batch 35 - Loss: 2.345860
[2025-05-10 23:28:31] === Epoch 40/50 Summary ===
Training Loss: 2.360142
Validation Loss: 4.768027
Learning Rate: 0.00003000
[2025-05-10 23:28:31] Generating detection visualizations for epoch 40...
[2025-05-10 23:28:31] Saved visualization to trained_models/custom_detector\visualizations\epoch_40\sample_1.png
[2025-05-10 23:28:32] Saved visualization to trained_models/custom_detector\visualizations\epoch_40\sample_2.png
[2025-05-10 23:28:32] Saved visualization to trained_models/custom_detector\visualizations\epoch_40\sample_3.png
[2025-05-10 23:28:33] Batch 0 - Loss: 2.827888
[2025-05-10 23:28:35] Batch 5 - Loss: 2.921778
[2025-05-10 23:28:36] Batch 10 - Loss: 2.877662
[2025-05-10 23:28:38] Batch 15 - Loss: 2.781869
[2025-05-10 23:28:40] Batch 20 - Loss: 2.833471
[2025-05-10 23:28:42] Batch 25 - Loss: 2.824765
[2025-05-10 23:28:43] Batch 30 - Loss: 2.798785
[2025-05-10 23:28:45] Batch 35 - Loss: 2.773014
[2025-05-10 23:28:47] Batch 40 - Loss: 2.758453
[2025-05-10 23:28:49] Batch 45 - Loss: 2.756298
[2025-05-10 23:28:50] Batch 50 - Loss: 2.753506
[2025-05-10 23:28:52] Batch 55 - Loss: 2.739823
[2025-05-10 23:28:54] Batch 60 - Loss: 2.720257
[2025-05-10 23:28:56] Batch 65 - Loss: 2.722267
[2025-05-10 23:28:57] Batch 70 - Loss: 2.707032
[2025-05-10 23:28:59] Batch 75 - Loss: 2.696664
[2025-05-10 23:29:01] Batch 80 - Loss: 2.701450
[2025-05-10 23:29:03] Batch 85 - Loss: 2.699044
[2025-05-10 23:29:04] Batch 90 - Loss: 2.687014
[2025-05-10 23:29:06] Batch 95 - Loss: 2.676899
[2025-05-10 23:29:13] === Epoch 41/50 Summary ===
Training Loss: 2.677100
Validation Loss: 4.903976
Learning Rate: 0.00003000
[2025-05-10 23:29:14] Batch 0 - Loss: 2.037972
[2025-05-10 23:29:15] Batch 5 - Loss: 2.436339
[2025-05-10 23:29:17] Batch 10 - Loss: 2.473794
[2025-05-10 23:29:19] Batch 15 - Loss: 2.540940
[2025-05-10 23:29:21] Batch 20 - Loss: 2.541927
[2025-05-10 23:29:23] Batch 25 - Loss: 2.535908
[2025-05-10 23:29:24] Batch 30 - Loss: 2.593667
[2025-05-10 23:29:26] Batch 35 - Loss: 2.572485
[2025-05-10 23:29:28] Batch 40 - Loss: 2.588183
[2025-05-10 23:29:30] Batch 45 - Loss: 2.579684
[2025-05-10 23:29:31] Batch 50 - Loss: 2.591046
[2025-05-10 23:29:33] Batch 55 - Loss: 2.593820
[2025-05-10 23:29:35] Batch 60 - Loss: 2.590308
[2025-05-10 23:29:37] Batch 65 - Loss: 2.580751
[2025-05-10 23:29:39] Batch 70 - Loss: 2.563603
[2025-05-10 23:29:40] Batch 75 - Loss: 2.555927
[2025-05-10 23:29:42] Batch 80 - Loss: 2.539197
[2025-05-10 23:29:44] Batch 85 - Loss: 2.538520
[2025-05-10 23:29:46] Batch 90 - Loss: 2.525429
[2025-05-10 23:29:48] Batch 95 - Loss: 2.544041
[2025-05-10 23:29:55] === Epoch 42/50 Summary ===
Training Loss: 2.541223
Validation Loss: 4.748210
Learning Rate: 0.00003000
[2025-05-10 23:29:55] Batch 0 - Loss: 2.931989
[2025-05-10 23:29:57] Batch 5 - Loss: 2.844046
[2025-05-10 23:29:59] Batch 10 - Loss: 2.697168
[2025-05-10 23:30:01] Batch 15 - Loss: 2.660835
[2025-05-10 23:30:02] Batch 20 - Loss: 2.633267
[2025-05-10 23:30:04] Batch 25 - Loss: 2.577631
[2025-05-10 23:30:06] Batch 30 - Loss: 2.554208
[2025-05-10 23:30:08] Batch 35 - Loss: 2.529939
[2025-05-10 23:30:10] Batch 40 - Loss: 2.557886
[2025-05-10 23:30:11] Batch 45 - Loss: 2.536885
[2025-05-10 23:30:13] Batch 50 - Loss: 2.520711
[2025-05-10 23:30:15] Batch 55 - Loss: 2.511015
[2025-05-10 23:30:17] Batch 60 - Loss: 2.507755
[2025-05-10 23:30:19] Batch 65 - Loss: 2.488217
[2025-05-10 23:30:21] Batch 70 - Loss: 2.479349
[2025-05-10 23:30:23] Batch 75 - Loss: 2.463779
[2025-05-10 23:30:25] Batch 80 - Loss: 2.469394
[2025-05-10 23:30:26] Batch 85 - Loss: 2.466122
[2025-05-10 23:30:28] Batch 90 - Loss: 2.452205
[2025-05-10 23:30:30] Batch 95 - Loss: 2.437206
[2025-05-10 23:30:38] === Epoch 43/50 Summary ===
Training Loss: 2.439329
Validation Loss: 4.794075
Learning Rate: 0.00000600
[2025-05-10 23:30:38] Batch 0 - Loss: 3.287061
[2025-05-10 23:30:40] Batch 5 - Loss: 2.294316
[2025-05-10 23:30:42] Batch 10 - Loss: 2.295273
[2025-05-10 23:30:44] Batch 15 - Loss: 2.310942
[2025-05-10 23:30:46] Batch 20 - Loss: 2.363595
[2025-05-10 23:30:47] Batch 25 - Loss: 2.317544
[2025-05-10 23:30:49] Batch 30 - Loss: 2.264784
[2025-05-10 23:30:51] Batch 35 - Loss: 2.236296
[2025-05-10 23:30:57] === Epoch 44/50 Summary ===
Training Loss: 2.243202
Validation Loss: 4.692662
Learning Rate: 0.00000600
[2025-05-10 23:30:58] Batch 0 - Loss: 2.562828
[2025-05-10 23:31:00] Batch 5 - Loss: 2.462823
[2025-05-10 23:31:01] Batch 10 - Loss: 2.511289
[2025-05-10 23:31:03] Batch 15 - Loss: 2.455574
[2025-05-10 23:31:05] Batch 20 - Loss: 2.493832
[2025-05-10 23:31:07] Batch 25 - Loss: 2.512882
[2025-05-10 23:31:08] Batch 30 - Loss: 2.535410
[2025-05-10 23:31:10] Batch 35 - Loss: 2.553607
[2025-05-10 23:31:12] Batch 40 - Loss: 2.527091
[2025-05-10 23:31:14] Batch 45 - Loss: 2.562888
[2025-05-10 23:31:16] Batch 50 - Loss: 2.551644
[2025-05-10 23:31:17] Batch 55 - Loss: 2.548102
[2025-05-10 23:31:19] Batch 60 - Loss: 2.534664
[2025-05-10 23:31:21] Batch 65 - Loss: 2.529742
[2025-05-10 23:31:23] Batch 70 - Loss: 2.529781
[2025-05-10 23:31:24] Batch 75 - Loss: 2.508085
[2025-05-10 23:31:26] Batch 80 - Loss: 2.501695
[2025-05-10 23:31:28] Batch 85 - Loss: 2.505215
[2025-05-10 23:31:30] Batch 90 - Loss: 2.502875
[2025-05-10 23:31:31] Batch 95 - Loss: 2.488587
[2025-05-10 23:31:39] === Epoch 45/50 Summary ===
Training Loss: 2.489236
Validation Loss: 4.696361
Learning Rate: 0.00000600
[2025-05-10 23:31:39] Generating detection visualizations for epoch 45...
[2025-05-10 23:31:39] Saved visualization to trained_models/custom_detector\visualizations\epoch_45\sample_1.png
[2025-05-10 23:31:39] Saved visualization to trained_models/custom_detector\visualizations\epoch_45\sample_2.png
[2025-05-10 23:31:40] Saved visualization to trained_models/custom_detector\visualizations\epoch_45\sample_3.png
[2025-05-10 23:31:40] Batch 0 - Loss: 2.765859
[2025-05-10 23:31:42] Batch 5 - Loss: 2.558227
[2025-05-10 23:31:44] Batch 10 - Loss: 2.393347
[2025-05-10 23:31:45] Batch 15 - Loss: 2.375614
[2025-05-10 23:31:47] Batch 20 - Loss: 2.352779
[2025-05-10 23:31:49] Batch 25 - Loss: 2.334280
[2025-05-10 23:31:51] Batch 30 - Loss: 2.336547
[2025-05-10 23:31:53] Batch 35 - Loss: 2.326431
[2025-05-10 23:31:54] Batch 40 - Loss: 2.328600
[2025-05-10 23:31:56] Batch 45 - Loss: 2.347333
[2025-05-10 23:31:58] Batch 50 - Loss: 2.338649
[2025-05-10 23:32:00] Batch 55 - Loss: 2.336527
[2025-05-10 23:32:02] Batch 60 - Loss: 2.349611
[2025-05-10 23:32:03] Batch 65 - Loss: 2.357275
[2025-05-10 23:32:05] Batch 70 - Loss: 2.345169
[2025-05-10 23:32:07] Batch 75 - Loss: 2.348498
[2025-05-10 23:32:09] Batch 80 - Loss: 2.333293
[2025-05-10 23:32:10] Batch 85 - Loss: 2.321037
[2025-05-10 23:32:12] Batch 90 - Loss: 2.335647
[2025-05-10 23:32:14] Batch 95 - Loss: 2.337076
[2025-05-10 23:32:22] === Epoch 46/50 Summary ===
Training Loss: 2.334558
Validation Loss: 4.651579
Learning Rate: 0.00000600
[2025-05-10 23:32:23] Batch 0 - Loss: 1.387917
[2025-05-10 23:32:24] Batch 5 - Loss: 1.967435
[2025-05-10 23:32:26] Batch 10 - Loss: 2.131735
[2025-05-10 23:32:28] Batch 15 - Loss: 2.231673
[2025-05-10 23:32:30] Batch 20 - Loss: 2.254708
[2025-05-10 23:32:32] Batch 25 - Loss: 2.220458
[2025-05-10 23:32:34] Batch 30 - Loss: 2.286198
[2025-05-10 23:32:36] Batch 35 - Loss: 2.287539
[2025-05-10 23:32:38] Batch 40 - Loss: 2.301740
[2025-05-10 23:32:39] Batch 45 - Loss: 2.293798
[2025-05-10 23:32:41] Batch 50 - Loss: 2.270216
[2025-05-10 23:32:43] Batch 55 - Loss: 2.237344
[2025-05-10 23:32:45] Batch 60 - Loss: 2.250377
[2025-05-10 23:32:46] Batch 65 - Loss: 2.247054
[2025-05-10 23:32:48] Batch 70 - Loss: 2.240136
[2025-05-10 23:32:50] Batch 75 - Loss: 2.232709
[2025-05-10 23:32:52] Batch 80 - Loss: 2.244329
[2025-05-10 23:32:53] Batch 85 - Loss: 2.247951
[2025-05-10 23:32:55] Batch 90 - Loss: 2.227236
[2025-05-10 23:32:57] Batch 95 - Loss: 2.227068
[2025-05-10 23:33:04] === Epoch 47/50 Summary ===
Training Loss: 2.223483
Validation Loss: 4.639347
Learning Rate: 0.00000600
[2025-05-10 23:33:04] Batch 0 - Loss: 2.261201
[2025-05-10 23:33:06] Batch 5 - Loss: 2.063225
[2025-05-10 23:33:08] Batch 10 - Loss: 2.107421
[2025-05-10 23:33:09] Batch 15 - Loss: 2.125867
[2025-05-10 23:33:11] Batch 20 - Loss: 2.139297
[2025-05-10 23:33:13] Batch 25 - Loss: 2.129339
[2025-05-10 23:33:15] Batch 30 - Loss: 2.132953
[2025-05-10 23:33:16] Batch 35 - Loss: 2.235421
[2025-05-10 23:33:22] === Epoch 48/50 Summary ===
Training Loss: 2.227368
Validation Loss: 4.670390
Learning Rate: 0.00000600
[2025-05-10 23:33:23] Batch 0 - Loss: 2.250968
[2025-05-10 23:33:25] Batch 5 - Loss: 2.493848
[2025-05-10 23:33:27] Batch 10 - Loss: 2.659159
[2025-05-10 23:33:29] Batch 15 - Loss: 2.658210
[2025-05-10 23:33:30] Batch 20 - Loss: 2.721882
[2025-05-10 23:33:32] Batch 25 - Loss: 2.681295
[2025-05-10 23:33:34] Batch 30 - Loss: 2.643202
[2025-05-10 23:33:36] Batch 35 - Loss: 2.631248
[2025-05-10 23:33:37] Batch 40 - Loss: 2.616305
[2025-05-10 23:33:39] Batch 45 - Loss: 2.568760
[2025-05-10 23:33:41] Batch 50 - Loss: 2.546081
[2025-05-10 23:33:43] Batch 55 - Loss: 2.528040
[2025-05-10 23:33:44] Batch 60 - Loss: 2.511766
[2025-05-10 23:33:46] Batch 65 - Loss: 2.498809
[2025-05-10 23:33:48] Batch 70 - Loss: 2.516424
[2025-05-10 23:33:50] Batch 75 - Loss: 2.484140
[2025-05-10 23:33:51] Batch 80 - Loss: 2.475585
[2025-05-10 23:33:53] Batch 85 - Loss: 2.473696
[2025-05-10 23:33:55] Batch 90 - Loss: 2.458910
[2025-05-10 23:33:57] Batch 95 - Loss: 2.452748
[2025-05-10 23:34:04] === Epoch 49/50 Summary ===
Training Loss: 2.459268
Validation Loss: 4.728719
Learning Rate: 0.00000600
[2025-05-10 23:34:04] Batch 0 - Loss: 2.104222
[2025-05-10 23:34:06] Batch 5 - Loss: 2.198222
[2025-05-10 23:34:08] Batch 10 - Loss: 2.245738
[2025-05-10 23:34:10] Batch 15 - Loss: 2.278397
[2025-05-10 23:34:12] Batch 20 - Loss: 2.337566
[2025-05-10 23:34:13] Batch 25 - Loss: 2.312623
[2025-05-10 23:34:15] Batch 30 - Loss: 2.336432
[2025-05-10 23:34:17] Batch 35 - Loss: 2.331839
[2025-05-10 23:34:19] Batch 40 - Loss: 2.350086
[2025-05-10 23:34:20] Batch 45 - Loss: 2.401669
[2025-05-10 23:34:22] Batch 50 - Loss: 2.421093
[2025-05-10 23:34:24] Batch 55 - Loss: 2.399868
[2025-05-10 23:34:26] Batch 60 - Loss: 2.383878
[2025-05-10 23:34:27] Batch 65 - Loss: 2.381280
[2025-05-10 23:34:29] Batch 70 - Loss: 2.381768
[2025-05-10 23:34:31] Batch 75 - Loss: 2.368174
[2025-05-10 23:34:33] Batch 80 - Loss: 2.369709
[2025-05-10 23:34:34] Batch 85 - Loss: 2.377313
[2025-05-10 23:34:36] Batch 90 - Loss: 2.351993
[2025-05-10 23:34:38] Batch 95 - Loss: 2.343836
[2025-05-10 23:34:45] === Epoch 50/50 Summary ===
Training Loss: 2.337111
Validation Loss: 4.664403
Learning Rate: 0.00000600
[2025-05-10 23:34:45] Generating detection visualizations for epoch 50...
[2025-05-10 23:34:46] Saved visualization to trained_models/custom_detector\visualizations\epoch_50\sample_1.png
[2025-05-10 23:34:46] Saved visualization to trained_models/custom_detector\visualizations\epoch_50\sample_2.png
[2025-05-10 23:34:46] Saved visualization to trained_models/custom_detector\visualizations\epoch_50\sample_3.png
[2025-05-10 23:34:46] === Training Completed ===
[2025-05-10 23:34:46] Best epoch: 47
[2025-05-10 23:34:46] Best validation loss: 4.639347
[2025-05-10 23:34:46] Model training completed in 30.21 minutes
[2025-05-10 23:34:47] Model saved to trained_models/custom_detector\final_model.keras
[2025-05-10 23:34:47] Training history plot saved to trained_models/custom_detector\training_history.png
[2025-05-10 23:34:47] === Valorant Detector Completed ===
